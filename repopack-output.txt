This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2025-08-02T14:17:53.152Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
ado-aml-cli-v2-templates/
  allocate-traffic.yml
  connect-to-workspace.yml
  create-compute.yml
  create-deployment.yml
  create-endpoint.yml
  install-aml-cli.yml
  install-az-cli.yml
  register-data.yml
  register-environment.yml
  run-pipeline.yml
  test-deployment.yml
amlws-assets/
  data/
    batch.csv
    data.csv
    data.yml
    request.json
    stage.csv
    stage.yml
  endpoints/
    batch/
      batch-deployment.yml
      batch-endpoint.yml
    online/
      online-deployment.yml
      online-endpoint.yml
  environment/
    automl-conda.yml
    automl-env.yml
    train-conda.yml
    train-env.yml
  pipelinejobs/
    dev-train.yml
    stage-test.yml
  src/
    evaluate.py
    prep.py
    register.py
    stageprep.py
    train.py
    train2.py
infrastructure/
  env-variables/
    config-infra-dev.yml
    config-infra-prod.yml
    config-infra-stage.yml
  modules/
    aml_computecluster.bicep
    aml_workspace.bicep
    application_insights.bicep
    container_registry.bicep
    key_vault.bicep
    storage_account.bicep
  pipelines/
    bicep-ado-deploy-infra.yml
  bicepconfig.json
  main.bicep
  main.json
mlops-ado-pipelines/
  dev-model-training.yml
  prod-batch-endpoint.yml
  prod-onine-endpoint.yml
  prod-register-in-production.yml
  stage-batch-endpoint.yml
  stage-model-testing.yml
  stage-online-endpoint.yml
  stage-register-in-staging.yml
README.md

================================================================
Repository Files
================================================================

================
File: ado-aml-cli-v2-templates/allocate-traffic.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

parameters:
- name: traffic_allocation
  type: string

steps:
  - task: AzureCLI@2
    displayName: Update traffic allocation
    inputs:
      azureSubscription: $(ado_service_connection_rg) #needs to have access at the RG level 
      scriptType: bash
      scriptLocation: inlineScript
      inlineScript: |

        # Check if the virtual environment exists, create if it doesn't
        if [ ! -d ~/myagent/$(virtual_environment) ]; then
          echo "Creating virtual environment $(virtual_environment)"
          python3 -m venv ~/myagent/$(virtual_environment)
        else
          echo "Virtual environment $(virtual_environment) already exists"
        fi

        # Activate the virtual environment
        echo "Activating $(virtual_environment) virtual environment"
        source ~/myagent/$(virtual_environment)/bin/activate

        set -e
        az ml online-endpoint update --name $(endpoint_name) --traffic "${{ parameters.traffic_allocation }}"

    env:
      PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

================
File: ado-aml-cli-v2-templates/connect-to-workspace.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

steps:
  - task: AzureCLI@2
    displayName: Connect to AML Workspace using CLI v2
    inputs:
      azureSubscription: $(ado_service_connection_aml_ws)
      scriptType: bash
      scriptLocation: inlineScript
      inlineScript: |
        az configure --defaults group=$(resource_group) workspace=$(aml_workspace)
        currentId=$(az account show -o tsv --query id | tr -d '"\r')
        echo "##vso[task.setvariable variable=subscription_id;]$currentId"
        JSON_STRING=$'{\n\t"subscription_id": "%s",\n\t"resource_group": "%s",\n\t"workspace_name": "%s"\n}'
        printf "$JSON_STRING" "$currentId" "$(resource_group)" "$(aml_workspace)"
        printf "$JSON_STRING" "$currentId" "$(resource_group)" "$(aml_workspace)" > config.json

================
File: ado-aml-cli-v2-templates/create-compute.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

parameters:
- name: cluster_name
  type: string
- name: size
  type: string
- name: min_instances
  type: number
- name: max_instances
  type: number
- name: cluster_tier
  type: string

steps:
  - task: AzureCLI@2
    displayName: Create compute cluster
    continueOnError: true
    inputs: 
      azureSubscription: $(ado_service_connection_rg) #needs to have access at the RG level 
      scriptType: bash
      scriptLocation: inlineScript
      inlineScript: |
        # Check if the virtual environment exists, create if it doesn't
        if [ ! -d ~/myagent/$(virtual_environment) ]; then
          echo "Creating virtual environment $(virtual_environment)"
          python3 -m venv ~/myagent/$(virtual_environment)
        else
          echo "Virtual environment $(virtual_environment) already exists"
        fi

        # Activate the virtual environment
        echo "Activating $(virtual_environment) virtual environment"
        source ~/myagent/$(virtual_environment)/bin/activate

        compute_name=$(az ml compute show -n ${{ parameters.cluster_name }} --query name -o tsv)
        if [[ -z "$compute_name" ]]
        then
          echo "Compute does not exist. Creating the cluster..."
          az ml compute create --name ${{ parameters.cluster_name }} \
                                  --type amlcompute \
                                  --size ${{ parameters.size }} \
                                  --min-instances ${{ parameters.min_instances }} \
                                  --max-instances ${{ parameters.max_instances }} \
                                  --tier ${{ parameters.cluster_tier }} 
        else
          echo "Compute exists. Skipping cluster creation."
          exit 0
        fi

    env:
      PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

================
File: ado-aml-cli-v2-templates/create-deployment.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

parameters:
- name: deployment_name
  type: string
- name: deployment_file
  type: string
- name: enable_monitoring
  type: string
  default: 'false'

steps:
  - task: AzureCLI@2
    displayName: Create deployment
    continueOnError: true
    inputs: 
      azureSubscription: $(ado_service_connection_rg) #needs to have access at the RG level 
      scriptType: bash
      scriptLocation: inlineScript
      inlineScript: |
        # Check if the virtual environment exists, create if it doesn't
        if [ ! -d ~/myagent/$(virtual_environment) ]; then
          echo "Creating virtual environment $(virtual_environment)"
          python3 -m venv ~/myagent/$(virtual_environment)
        else
          echo "Virtual environment $(virtual_environment) already exists"
        fi

        # Activate the virtual environment
        echo "Activating $(virtual_environment) virtual environment"
        source ~/myagent/$(virtual_environment)/bin/activate

        set -o xtrace
        az ml $(endpoint_type)-deployment create --name ${{ parameters.deployment_name }} --endpoint $(endpoint_name) \
          -f ${{ parameters.deployment_file }}

    env:
      PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

================
File: ado-aml-cli-v2-templates/create-endpoint.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

parameters: 
- name: endpoint_file
  type: string

steps:
  - task: AzureCLI@2
    displayName: Create online/batch endpoint 
    continueOnError: true
    inputs: 
      azureSubscription: $(ado_service_connection_rg) #needs to have access at the RG level 
      scriptType: bash
      scriptLocation: inlineScript
      inlineScript: |
        # Check if the virtual environment exists, create if it doesn't
        if [ ! -d ~/myagent/$(virtual_environment) ]; then
          echo "Creating virtual environment $(virtual_environment)"
          python3 -m venv ~/myagent/$(virtual_environment)
        else
          echo "Virtual environment $(virtual_environment) already exists"
        fi

        # Activate the virtual environment
        echo "Activating $(virtual_environment) virtual environment"
        source ~/myagent/$(virtual_environment)/bin/activate
        
        ENDPOINT_EXISTS=$(az ml $(endpoint_type)-endpoint list -o tsv --query "[?name=='$(endpoint_name)'][name]" | wc -l)
        echo $ENDPOINT_NAME $ENDPOINT_EXISTS
        az ml $(endpoint_type)-endpoint list -o tsv

        if [[ ENDPOINT_EXISTS -ne 1 ]]; then
            az ml $(endpoint_type)-endpoint create --name $(endpoint_name) -f ${{ parameters.endpoint_file }}
        else
            echo "Endpoint exists"
        fi

    env:
      PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

================
File: ado-aml-cli-v2-templates/install-aml-cli.yml
================
steps:
  - task: AzureCLI@2
    displayName: Install AML CLI v2
    inputs:
      azureSubscription: $(ado_service_connection_aml_ws)
      scriptType: bash
      scriptLocation: inlineScript
      workingDirectory: $(System.DefaultWorkingDirectory)
      inlineScript: |
        set -e # fail on error
        
        # Check if we're in the virtual environment, activate only if needed
        if [[ "$VIRTUAL_ENV" != */myagent/$(virtual_environment) ]]; then
          echo "Activating $(virtual_environment) virtual environment"
          source ~/myagent/$(virtual_environment)/bin/activate
        else
          echo "Already in $(virtual_environment) virtual environment"
        fi
        
        echo "Python version: $(python --version)"
        echo "Pip version: $(pip --version)"

        # Display Azure CLI version
        az version

        # Add and update the ml extension
        az extension  add -n ml

        # List all extensions
        az extension list

        echo "AML CLI v2 installation completed."

    env:
      PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

================
File: ado-aml-cli-v2-templates/install-az-cli.yml
================
steps:
  - task: AzureCLI@2
    displayName: Install AZ CLI and dependencies
    inputs:
      azureSubscription: $(ado_service_connection_aml_ws)
      scriptType: bash
      scriptLocation: inlineScript
      workingDirectory: $(System.DefaultWorkingDirectory)
      inlineScript: |
        set -e # fail on error
        
        # Check if the virtual environment exists, create if it doesn't
        if [ ! -d ~/myagent/$(virtual_environment) ]; then
          echo "Creating virtual environment $(virtual_environment)"
          python3 -m venv ~/myagent/$(virtual_environment)
        else
          echo "Virtual environment $(virtual_environment) already exists"
        fi

        # Check if we're in the virtual environment, activate only if needed
        if [[ "$VIRTUAL_ENV" != */myagent/$(virtual_environment) ]]; then
          echo "Activating $(virtual_environment) virtual environment"
          source ~/myagent/$(virtual_environment)/bin/activate
        else
          echo "Already in $(virtual_environment) virtual environment"
        fi
        
        echo "Python version: $(python --version)"
        echo "Pip version: $(pip --version)"

        # Upgrade pip, setuptools, and wheel
        python -m pip install --upgrade pip setuptools wheel
        # Install or upgrade azure-cli
        python -m pip install --upgrade azure-cli

        # Function to compare versions
        version_gt() { test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1"; }

        # Function to check and install package
        check_and_install() {
          package=$1
          required_version=$2
          installed_version=$(pip show $package 2>/dev/null | grep Version | cut -d ' ' -f 2)
          
          if [ -z "$installed_version" ]; then
            echo "Installing $package $required_version"
            pip install "$package==$required_version"
          elif version_gt $required_version $installed_version; then
            echo "Updating $package from $installed_version to $required_version"
            pip install --upgrade "$package==$required_version"
          else
            echo "$package is already at version $installed_version (required: $required_version)"
          fi
        }

        # List of packages and their required versions
        packages="azure-ai-ml:1.1.0 azure-common:1.1.28 azure-core:1.26.1 azure-identity:1.10.0 azure-mgmt-core:1.3.0 azure-storage-blob:12.14.1 azure-storage-file-datalake:12.9.1 azure-storage-file-share:12.7.0"

        # Check and install packages if necessary
        echo "$packages" | tr ' ' '\n' | while IFS=':' read -r package version; do
          check_and_install "$package" "$version"
        done

        # Update these packages to latest versions
        pip install --upgrade pyOpenSSL cryptography requests

        # Display Azure CLI version
        az version

        echo "Azure CLI and dependencies installation completed."

    env:
      PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

================
File: ado-aml-cli-v2-templates/register-data.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

parameters:
- name: data_type
  type: string
- name: data_name
  type: string
- name: data_file
  type: string

steps:
  - task: AzureCLI@2
    displayName: Register Azure ML data asset
    continueOnError: true
    inputs: 
      azureSubscription: $(ado_service_connection_rg) #needs to have access at the RG level 
      scriptType: bash
      workingDirectory: $(System.DefaultWorkingDirectory)
      scriptLocation: inlineScript
      inlineScript: |
        # Check if the virtual environment exists, create if it doesn't
        if [ ! -d ~/myagent/$(virtual_environment) ]; then
          echo "Creating virtual environment $(virtual_environment)"
          python3 -m venv ~/myagent/$(virtual_environment)
        else
          echo "Virtual environment $(virtual_environment) already exists"
        fi

        # Activate the virtual environment
        echo "Activating $(virtual_environment) virtual environment"
        source ~/myagent/$(virtual_environment)/bin/activate

        az ml data create --file ${{ parameters.data_file }} --name ${{ parameters.data_name }} --type ${{ parameters.data_type }}

    env:
      PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

================
File: ado-aml-cli-v2-templates/register-environment.yml
================
steps:
  - task: AzureCLI@2
    displayName: Register Azure ML environment 
    inputs: 
      azureSubscription: $(ado_service_connection_rg)
      scriptType: bash
      workingDirectory: $(System.DefaultWorkingDirectory)
      scriptLocation: inlineScript
      inlineScript: |
        set -e # fail on error

        # Check if the virtual environment exists, create if it doesn't
        if [ ! -d ~/myagent/$(virtual_environment) ]; then
          echo "Creating virtual environment $(virtual_environment)"
          python3 -m venv ~/myagent/$(virtual_environment)
        else
          echo "Virtual environment $(virtual_environment) already exists"
        fi

        # Activate the virtual environment
        echo "Activating $(virtual_environment) virtual environment"
        source ~/myagent/$(virtual_environment)/bin/activate

        az ml environment create --name ${{ parameters.environment_name }} --file ${{ parameters.environment_file }}

    env:
      PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

================
File: ado-aml-cli-v2-templates/run-pipeline.yml
================
steps:
  - task: AzureCLI@2
    displayName: Run Azure ML pipeline
    continueOnError: true
    inputs: 
      azureSubscription: $(ado_service_connection_rg)
      scriptType: bash
      workingDirectory: $(System.DefaultWorkingDirectory)
      scriptLocation: inlineScript
      inlineScript: |
        # Check if the virtual environment exists, create if it doesn't
        if [ ! -d ~/myagent/$(virtual_environment) ]; then
          echo "Creating virtual environment $(virtual_environment)"
          python3 -m venv ~/myagent/$(virtual_environment)
        else
          echo "Virtual environment $(virtual_environment) already exists"
        fi

        # Activate the virtual environment
        source ~/myagent/$(virtual_environment)/bin/activate

        # Install or update the Azure ML CLI extension
        az extension add --name ml --upgrade --yes

        az version
        az extension list

        # Check if 'ml' extension is installed
        if ! az extension show --name ml &> /dev/null; then
          echo "Failed to install 'ml' extension. Exiting."
          exit 1
        fi

        run_id=$(az ml job create -f ${{ parameters.pipeline_file }} \
          --set experiment_name=${{ parameters.experiment_name }} \
          --set inputs.enable_monitoring=${{ parameters.enable_monitoring }} \
          --set inputs.modelname=${{ parameters.modelname }} \
          display_name=${{ parameters.display_name }} --query name -o tsv)
        if [[ -z "$run_id" ]]
        then
          echo "Job creation failed"
          exit 3
        fi
        az ml job show -n $run_id --web
        status=$(az ml job show -n $run_id --query status -o tsv)
        if [[ -z "$status" ]]
        then
          echo "Status query failed"
          exit 4
        fi
        running=("NotStarted" "Queued" "Starting" "Preparing" "Running" "Finalizing" "CancelRequested")
        while [[ ${running[*]} =~ $status ]]
        do
          sleep 15 
          status=$(az ml job show -n $run_id --query status -o tsv)
          echo $status
        done
        if [[ "$status" != "Completed" ]]  
        then
          echo "Training Job failed or canceled"
          exit 3
        fi
    env:
      PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

================
File: ado-aml-cli-v2-templates/test-deployment.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

parameters:
  - name: deployment_name
    type: string
  - name: sample_request
    type: string
  - name: request_type
    type: string


steps:
  - task: AzureCLI@2
    displayName: Test deployment
    inputs: 
      azureSubscription: $(ado_service_connection_rg) #needs to have access at the RG level 
      scriptType: bash
      workingDirectory: $(System.DefaultWorkingDirectory)
      scriptLocation: inlineScript
      inlineScript: |
        # Check if the virtual environment exists, create if it doesn't
        if [ ! -d ~/myagent/$(virtual_environment) ]; then
          echo "Creating virtual environment $(virtual_environment)"
          python3 -m venv ~/myagent/$(virtual_environment)
        else
          echo "Virtual environment $(virtual_environment) already exists"
        fi

        # Activate the virtual environment
        echo "Activating $(virtual_environment) virtual environment"
        source ~/myagent/$(virtual_environment)/bin/activate

        set -e
        RESPONSE=$(az ml $(endpoint_type)-endpoint invoke -n $(endpoint_name) --deployment-name ${{ parameters.deployment_name }} --request-file ${{ parameters.sample_request }})
        echo $RESPONSE
    condition: and(succeeded(), eq(variables['endpoint_type'], 'online'))
    env:
      PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)
    
  - task: AzureCLI@2
    displayName: Test deployment
    inputs: 
      azureSubscription: $(ado_service_connection_rg) #needs to have access at the RG level 
      scriptType: bash
      workingDirectory: $(System.DefaultWorkingDirectory)
      scriptLocation: inlineScript
      inlineScript: |
        # Check if the virtual environment exists, create if it doesn't
        if [ ! -d ~/myagent/$(virtual_environment) ]; then
          echo "Creating virtual environment $(virtual_environment)"
          python3 -m venv ~/myagent/$(virtual_environment)
        else
          echo "Virtual environment $(virtual_environment) already exists"
        fi

        # Activate the virtual environment
        echo "Activating $(virtual_environment) virtual environment"
        source ~/myagent/$(virtual_environment)/bin/activate

        set -e
        JOB_NAME=$(az ml $(endpoint_type)-endpoint invoke --name $(endpoint_name) --deployment-name ${{ parameters.deployment_name }} --input ${{ parameters.sample_request }} --input-type ${{ parameters.request_type }} --query name -o tsv)
        az ml job show -n $JOB_NAME --web
        az ml job stream -n $JOB_NAME

        STATUS=$(az ml job show -n $JOB_NAME --query status -o tsv)
        echo $STATUS
        if [[ $STATUS == "Completed" ]]
        then
          echo "Job completed"
        elif [[ $STATUS ==  "Failed" ]]
        then
          echo "Job failed"
          exit 1
        else 
          echo "Job status not failed or completed"
          exit 2
        fi
    condition: and(succeeded(), eq(variables['endpoint_type'], 'batch'))
    env:
      PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

================
File: amlws-assets/data/data.yml
================
$schema: https://azuremlschemas.azureedge.net/latest/data.schema.json

# Supported paths include:
# local: ./<path>
# blob:  https://<account_name>.blob.core.windows.net/<container_name>/<path>
# ADLS gen2: abfss://<file_system>@<account_name>.dfs.core.windows.net/<path>/
# Datastore: azureml://datastores/<data_store_name>/paths/<path>
type: uri_file
name: $(Build.Repository.Name)-data
description: $(Build.Repository.Name) dataset
path: data.csv

================
File: amlws-assets/data/stage.yml
================
$schema: https://azuremlschemas.azureedge.net/latest/data.schema.json

# Supported paths include:
# local: ./<path>
# blob:  https://<account_name>.blob.core.windows.net/<container_name>/<path>
# ADLS gen2: abfss://<file_system>@<account_name>.dfs.core.windows.net/<path>/
# Datastore: azureml://datastores/<data_store_name>/paths/<path>
type: uri_file
name: $(Build.Repository.Name)-stage-data
description: $(Build.Repository.Name) stage dataset
path: stage.csv

================
File: amlws-assets/endpoints/batch/batch-deployment.yml
================
$schema: https://azuremlschemas.azureedge.net/latest/batchDeployment.schema.json
name: batch-dp
endpoint_name: $(Build.Repository.Name)-batch
model: azureml:automl-model@latest
compute: azureml:batch-cluster
resources:
  instance_count: 1
max_concurrency_per_instance: 2
mini_batch_size: 10
output_action: append_row
output_file_name: predictions.csv
retry_settings:
  max_retries: 3
  timeout: 30
error_threshold: -1
logging_level: info

================
File: amlws-assets/endpoints/batch/batch-endpoint.yml
================
$schema: https://azuremlschemas.azureedge.net/latest/batchEndpoint.schema.json
name: $(Build.Repository.Name)-batch
description: Model endpoint
auth_mode: aad_token

================
File: amlws-assets/endpoints/online/online-deployment.yml
================
$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json
name: blue
endpoint_name: $(Build.Repository.Name)-online
model: azureml:automl-model@latest
instance_type: Standard_DS3_v2
instance_count: 1

================
File: amlws-assets/endpoints/online/online-endpoint.yml
================
$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineEndpoint.schema.json
name: $(Build.Repository.Name)-online
description: Model endpoint
auth_mode: key

================
File: amlws-assets/environment/automl-conda.yml
================
channels:
  - conda-forge
dependencies:
  - python=3.10
  - pip
  - pip:
    - azureml-sdk==1.57.0
    - azureml-train-automl-runtime==1.57.0
    - azureml-widgets==1.57.0
    - azureml-mlflow==1.57.0
    - azure-ai-ml==1.12.1
    - pyarrow==14.0.2
    - pandas==1.3.5
    - numpy~=1.22.4
    - joblib==1.2.0
    - matplotlib~=3.7.1
    - azure-core~=1.26.4
    - azure-identity~=1.7.0
    - azure-storage-queue~=12.6.0
    - opentelemetry-api~=1.20.0
    - opentelemetry-sdk~=1.20.0
    - argcomplete<=3.4.0
    - attrs<=23.2.0
    - cachetools<=5.4.0
    - certifi<=2024.7.4
    - cffi<=1.16.0
    - databricks-sdk<=0.29.0
    - dill<=0.3.8
    - fire<=0.6.0
    - fsspec<=2024.6.1
    - google-auth<=2.32.0
    - jsonpickle<=3.2.2
    - mlflow-skinny<=2.15.0
    - msal<=1.30.0
    - msgpack<=1.0.8
    - paramiko<=3.4.0
    - pyasn1<=0.6.0
    - rpds-py<=0.19.1
    - scikit-learn<=1.5.1
    - sympy<=1.13.1
    - urllib3<=1.26.19
    - zipp<=3.19.2
    - pytz<=2024.1
    - git+https://github.com/microsoft/AzureML-Observability#subdirectory=aml-obs-client
    - git+https://github.com/microsoft/AzureML-Observability#subdirectory=aml-obs-collector
    - isodate<=0.6.1
    - jsonschema-specifications<=2023.12.1
    - termcolor<=2.4.0
    - toolz<=0.12.1

================
File: amlws-assets/environment/automl-env.yml
================
$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json
name: automl-env
image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04
conda_file: automl-conda.yml
description: Environment created from a Docker image plus Conda environment to automl train $(Build.Repository.Name) model.

================
File: amlws-assets/environment/train-conda.yml
================
channels:
  - defaults
  - conda-forge
dependencies:
  - python=3.10
  - pip
  - pip:
    - azureml-mlflow
    - azure-ai-ml
    - pyarrow
    - scikit-learn
    - pandas
    - joblib
    - matplotlib
    - git+https://github.com/microsoft/AzureML-Observability#subdirectory=aml-obs-client
    - git+https://github.com/microsoft/AzureML-Observability#subdirectory=aml-obs-collector

================
File: amlws-assets/environment/train-env.yml
================
$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json
name: $(Build.Repository.Name)-train-env
image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04
conda_file: ../../../amlws-assets/environment/train-conda.yml
description: Environment created from a Docker image plus Conda environment to train $(Build.Repository.Name) model.

================
File: amlws-assets/pipelinejobs/dev-train.yml
================
$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json
type: pipeline
experiment_name: $(Build.Repository.Name)-training
description: Training Pipeline to train a model that predicts $(Build.Repository.Name) price

# <inputs_and_outputs>
inputs:
  input:
    type: uri_file
    path: azureml:data@latest
  enable_monitoring:
    type: boolean
  modelname:
    type: string
  table_name: 'monitoring'

outputs:
  train_data:
  val_data:
  test_data:
  trained_model:
  evaluation_output:
  model_info_output_path:
# </inputs_and_outputs>

# <jobs>
settings:
  default_datastore: azureml:workspaceblobstore
  default_compute: azureml:cpu-cluster
  continue_on_step_failure: false

jobs:
  prep_data:
    name: prep_data
    display_name: prep-data
    code: ../src
    command: >-
      python prep.py
      --raw_data ${{inputs.raw_data}}
      --train_data ${{outputs.train_data}}
      --val_data ${{outputs.val_data}}
      --test_data ${{outputs.test_data}}
      --enable_monitoring ${{inputs.enable_monitoring}}
      --table_name ${{inputs.table_name}}
    environment: azureml:automl-env@latest
    inputs:
      raw_data: ${{parent.inputs.input}}
      enable_monitoring: ${{parent.inputs.enable_monitoring}}
      table_name: ${{parent.inputs.table_name}}
    outputs:
      train_data: ${{parent.outputs.train_data}}
      val_data: ${{parent.outputs.val_data}}
      test_data: ${{parent.outputs.test_data}}

  train_model:
    name: train_model
    display_name: train-model
    code: ../src
    command: >-
      python train.py
      --modelname ${{inputs.modelname}}
      --train_data ${{inputs.train_data}}
      --model_output ${{outputs.model_output}}
    environment: azureml:automl-env@latest
    inputs:
      modelname: ${{parent.inputs.modelname}}
      train_data: ${{parent.jobs.prep_data.outputs.train_data}}
    outputs:
      model_output: ${{parent.outputs.trained_model}}

  evaluate_model:
    name: evaluate_model
    display_name: evaluate-model
    code: ../src
    command: >-
      python evaluate.py
      --model_name ${{inputs.model_name}}
      --model_input ${{inputs.model_input}}
      --test_data ${{inputs.test_data}}
      --evaluation_output ${{outputs.evaluation_output}}
    environment: azureml:automl-env@latest
    inputs:
      model_name: "${{parent.inputs.modelname}}-model"
      model_input: ${{parent.jobs.train_model.outputs.model_output}}
      test_data: ${{parent.jobs.prep_data.outputs.test_data}}
    outputs:
      evaluation_output: ${{parent.outputs.evaluation_output}}

  register_model:
    name: register_model
    display_name: register-model
    code: ../src
    command: >-
      python register.py
      --model_name ${{inputs.model_name}}
      --model_path ${{inputs.model_path}}
      --evaluation_output ${{inputs.evaluation_output}}
      --model_info_output_path ${{outputs.model_info_output_path}}
    environment: azureml:automl-env@latest
    inputs:
      model_name: "${{parent.inputs.modelname}}-model"
      model_path: ${{parent.jobs.train_model.outputs.model_output}}
      evaluation_output: ${{parent.jobs.evaluate_model.outputs.evaluation_output}}
    outputs:
      model_info_output_path: ${{parent.outputs.model_info_output_path}}
# </jobs>

================
File: amlws-assets/pipelinejobs/stage-test.yml
================
$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json
type: pipeline
experiment_name: $(Build.Repository.Name)-evaluation
description: Evaluation Pipeline to evaluate the latest model for $(Build.Repository.Name) price prediction

inputs:
  input:
    type: uri_file
    path: azureml:data@latest
  enable_monitoring:
    type: boolean
  modelname:
    type: string
  table_name: 'monitoring'
  model_input:
    type: mlflow_model
    path: azureml:automl-model@latest

outputs:
  test_data:
  evaluation_output:

settings:
  default_datastore: azureml:workspaceblobstore
  default_compute: azureml:cpu-cluster
  continue_on_step_failure: false

jobs:
  prep_data:
    name: prep_data
    display_name: prep-data
    code: ../src
    command: >-
      python stageprep.py
      --raw_data ${{inputs.raw_data}}
      --test_data ${{outputs.test_data}}
      --enable_monitoring ${{inputs.enable_monitoring}}
      --table_name ${{inputs.table_name}}
    environment: azureml:automl-env@latest
    inputs:
      raw_data: ${{parent.inputs.input}}
      enable_monitoring: ${{parent.inputs.enable_monitoring}}
      table_name: ${{parent.inputs.table_name}}
    outputs:
      test_data: ${{parent.outputs.test_data}}

  evaluate_model:
    name: evaluate_model
    display_name: evaluate-model
    code: ../src
    command: >-
      python evaluate.py
      --model_name ${{inputs.model_name}}
      --model_input ${{inputs.model_input}}
      --test_data ${{inputs.test_data}}
      --evaluation_output ${{outputs.evaluation_output}}
    environment: azureml:automl-env@latest
    inputs:
      model_input: ${{parent.inputs.model_input}}
      model_name: "${{parent.inputs.modelname}}-model"
      test_data: ${{parent.jobs.prep_data.outputs.test_data}}
    outputs:
      evaluation_output: ${{parent.outputs.evaluation_output}}

================
File: amlws-assets/src/evaluate.py
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
"""
Evaluates trained ML model using test dataset.
Saves predictions, evaluation results and deploy flag.
"""

import argparse
from pathlib import Path

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

import mlflow
import mlflow.pyfunc
from mlflow.tracking import MlflowClient

TARGET_COL = "cost"

NUMERIC_COLS = [
    "distance",
    "dropoff_latitude",
    "dropoff_longitude",
    "passengers",
    "pickup_latitude",
    "pickup_longitude",
    "pickup_weekday",
    "pickup_month",
    "pickup_monthday",
    "pickup_hour",
    "pickup_minute",
    "pickup_second",
    "dropoff_weekday",
    "dropoff_month",
    "dropoff_monthday",
    "dropoff_hour",
    "dropoff_minute",
    "dropoff_second",
]

CAT_NOM_COLS = [
    "store_forward",
    "vendor",
]

CAT_ORD_COLS = [
]

def parse_args():
    '''Parse input arguments'''
    parser = argparse.ArgumentParser("predict")
    parser.add_argument("--model_name", type=str, help="Name of registered model")
    parser.add_argument("--model_input", type=str, help="Path of input model")
    parser.add_argument("--test_data", type=str, help="Path to test dataset")
    parser.add_argument("--evaluation_output", type=str, help="Path of eval results")
    parser.add_argument("--runner", type=str, help="Local or Cloud Runner", default="CloudRunner")
    args = parser.parse_args()
    return args

def main(args):
    '''Read trained model and test dataset, evaluate model and save result'''

    # Load the test data
    test_data = pd.read_parquet(Path(args.test_data))

    # Split the data into inputs and outputs
    y_test = test_data[TARGET_COL]
    X_test = test_data[NUMERIC_COLS + CAT_NOM_COLS + CAT_ORD_COLS]

    # Load the model from input port using mlflow.pyfunc
    model = mlflow.pyfunc.load_model(args.model_input)

    # ---------------- Model Evaluation ---------------- #
    yhat_test, score = model_evaluation(X_test, y_test, model, args.evaluation_output)

    # ----------------- Model Promotion ---------------- #
    if args.runner == "CloudRunner":
        predictions, deploy_flag = model_promotion(args.model_name, args.evaluation_output, X_test, y_test, yhat_test, score)

def model_evaluation(X_test, y_test, model, evaluation_output):
    # Get predictions
    yhat_test = model.predict(X_test)

    # Save the output data with feature columns, predicted cost, and actual cost in csv file
    output_data = X_test.copy()
    output_data["real_label"] = y_test
    output_data["predicted_label"] = yhat_test
    output_data.to_csv((Path(evaluation_output) / "predictions.csv"))

    # Evaluate Model performance with the test set
    r2 = r2_score(y_test, yhat_test)
    mse = mean_squared_error(y_test, yhat_test)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, yhat_test)

    # Print score report to a text file
    with open((Path(evaluation_output) / "score.txt"), "w") as outfile:
        outfile.write(f"Scored with the following model:\n{model}\n")
        outfile.write(f"Mean squared error: {mse:.2f}\n")
        outfile.write(f"Root mean squared error: {rmse:.2f}\n")
        outfile.write(f"Mean absolute error: {mae:.2f}\n")
        outfile.write(f"Coefficient of determination: {r2:.2f}\n")

    mlflow.log_metric("test r2", r2)
    mlflow.log_metric("test mse", mse)
    mlflow.log_metric("test rmse", rmse)
    mlflow.log_metric("test mae", mae)

    # Visualize results
    plt.figure(figsize=(10, 6))
    plt.scatter(y_test, yhat_test, color='black', alpha=0.6)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel("Real value")
    plt.ylabel("Predicted value")
    plt.title("Comparing Model Predictions to Real values - Test Data")
    plt.savefig("predictions.png")
    mlflow.log_artifact("predictions.png")

    return yhat_test, r2

def model_promotion(model_name, evaluation_output, X_test, y_test, yhat_test, score):
    scores = {}
    predictions = {}

    client = MlflowClient()

    for model_run in client.search_model_versions(f"name='{model_name}'"):
        model_version = model_run.version
        mdl = mlflow.pyfunc.load_model(model_uri=f"models:/{model_name}/{model_version}")
        predictions[f"{model_name}:{model_version}"] = mdl.predict(X_test)
        scores[f"{model_name}:{model_version}"] = r2_score(y_test, predictions[f"{model_name}:{model_version}"])

    if scores:
        if score >= max(list(scores.values())):
            deploy_flag = 1
        else:
            deploy_flag = 1
    else:
        deploy_flag = 1
    print(f"Deploy flag: {deploy_flag}")

    with open((Path(evaluation_output) / "deploy_flag"), 'w') as outfile:
        outfile.write(f"{int(deploy_flag)}")

    # add current model score and predictions
    scores["current model"] = score
    predictions["current model"] = yhat_test

    perf_comparison_plot = pd.DataFrame(scores, index=["r2 score"]).plot(kind='bar', figsize=(15, 10))
    perf_comparison_plot.figure.savefig("perf_comparison.png")
    perf_comparison_plot.figure.savefig(Path(evaluation_output) / "perf_comparison.png")

    mlflow.log_metric("deploy flag", bool(deploy_flag))
    mlflow.log_artifact("perf_comparison.png")

    return predictions, deploy_flag

if __name__ == "__main__":
    mlflow.start_run()
    args = parse_args()
    lines = [
        f"Model name: {args.model_name}",
        f"Model path: {args.model_input}",
        f"Test data path: {args.test_data}",
        f"Evaluation output path: {args.evaluation_output}",
    ]
    for line in lines:
        print(line)
    main(args)
    mlflow.end_run()

================
File: amlws-assets/src/prep.py
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
"""
Prepares raw data and provides training, validation and test datasets
"""

import argparse

from pathlib import Path
import os
import numpy as np
import pandas as pd

import mlflow

TARGET_COL = "cost"

NUMERIC_COLS = [
    "distance",
    "dropoff_latitude",
    "dropoff_longitude",
    "passengers",
    "pickup_latitude",
    "pickup_longitude",
    "pickup_weekday",
    "pickup_month",
    "pickup_monthday",
    "pickup_hour",
    "pickup_minute",
    "pickup_second",
    "dropoff_weekday",
    "dropoff_month",
    "dropoff_monthday",
    "dropoff_hour",
    "dropoff_minute",
    "dropoff_second",
]

CAT_NOM_COLS = [
    "store_forward",
    "vendor",
]

CAT_ORD_COLS = [
]
TARGET_COL = "cost"

def parse_args():
    '''Parse input arguments'''

    parser = argparse.ArgumentParser("prep")
    parser.add_argument("--raw_data", type=str, help="Path to raw data")
    parser.add_argument("--train_data", type=str, help="Path to train dataset")
    parser.add_argument("--val_data", type=str, help="Path to test dataset")
    parser.add_argument("--test_data", type=str, help="Path to test dataset")

    parser.add_argument("--enable_monitoring", type=str, help="enable logging to ADX")
    parser.add_argument("--table_name", type=str, default="mlmonitoring", help="Table name in ADX for logging")

    args = parser.parse_args()

    return args

def log_training_data(df, table_name):
    from obs.collector import Online_Collector
    collector = Online_Collector(table_name)
    collector.batch_collect(df)

def main(args):
    '''Read, split, and save datasets'''

    # ------------ Reading Data ------------ #
    # -------------------------------------- #

    data = pd.read_csv((Path(args.raw_data)))
    data = data[NUMERIC_COLS + CAT_NOM_COLS + CAT_ORD_COLS + [TARGET_COL]]

    # ------------- Split Data ------------- #
    # -------------------------------------- #

    # Split data into train, val and test datasets

    random_data = np.random.rand(len(data))

    msk_train = random_data < 0.7
    msk_val = (random_data >= 0.7) & (random_data < 0.85)
    msk_test = random_data >= 0.85

    train = data[msk_train]
    val = data[msk_val]
    test = data[msk_test]
    test = data[msk_test]

    mlflow.log_metric('train size', train.shape[0])
    mlflow.log_metric('val size', val.shape[0])
    mlflow.log_metric('test size', test.shape[0])

    train.to_parquet((Path(args.train_data) / "train.parquet"))
    val.to_parquet((Path(args.val_data) / "val.parquet"))
    test.to_parquet((Path(args.test_data) / "test.parquet"))
    train.to_parquet((Path(args.train_data) / "train.parquet"))
    val.to_parquet((Path(args.val_data) / "val.parquet"))
    test.to_parquet((Path(args.test_data) / "test.parquet"))

    if (args.enable_monitoring.lower() == 'true' or args.enable_monitoring == '1' or args.enable_monitoring.lower() == 'yes'):
        log_training_data(data, args.table_name)



if __name__ == "__main__":

    mlflow.start_run()

    # ---------- Parse Arguments ----------- #
    # -------------------------------------- #

    args = parse_args()

    lines = [
        f"Raw data path: {args.raw_data}",
        f"Train dataset output path: {args.train_data}",
        f"Val dataset output path: {args.val_data}",
        f"Test dataset path: {args.test_data}",

    ]

    for line in lines:
        print(line)

    main(args)

    mlflow.end_run()

================
File: amlws-assets/src/register.py
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
"""
Registers trained ML model if deploy flag is True.
"""

import argparse
from pathlib import Path
import mlflow
import os
import json
from train import WrappedModel  # Import WrappedModel from train.py

def parse_args():
    '''Parse input arguments'''
    parser = argparse.ArgumentParser()
    parser.add_argument('--model_name', type=str, help='Name under which model will be registered')
    parser.add_argument('--model_path', type=str, help='Model directory')
    parser.add_argument('--evaluation_output', type=str, help='Path of eval results')
    parser.add_argument(
        "--model_info_output_path", type=str, help="Path to write model info JSON"
    )
    args, _ = parser.parse_known_args()
    print(f'Arguments: {args}')
    return args

def main(args):
    '''Loads model, registers it if deploy flag is True'''

    # Check deploy flag
    with open((Path(args.evaluation_output) / "deploy_flag"), 'rb') as infile:
        deploy_flag = int(infile.read())
        
    mlflow.log_metric("deploy flag", int(deploy_flag))

    # Proceed only if deploy flag is set
    if deploy_flag == 1:
        print(f"Registering {args.model_name}")

        # Load the model from the specified path
        model = mlflow.pyfunc.load_model(args.model_path)

        # Wrap the loaded model
        wrapped_model = WrappedModel(model)

        # Register the wrapped model using mlflow
        registered_model = mlflow.pyfunc.log_model(
            artifact_path="model",
            python_model=wrapped_model,  # Pass the wrapped model here
            registered_model_name=args.model_name
        )

        # Write model info as JSON
        print("Writing JSON")

        # Update this part to retrieve the version from registered_model instead of model
        model_info = {"id": f"{args.model_name}:{registered_model.version if hasattr(registered_model, 'version') else 'unknown'}"} 

        output_path = os.path.join(args.model_info_output_path, "model_info.json")
        with open(output_path, "w") as of:
            json.dump(model_info, of)
    else:
        print("Model will not be registered!")

if __name__ == "__main__":
    mlflow.start_run()

    args = parse_args()

    # Print arguments for debugging
    print(f"Model name: {args.model_name}")
    print(f"Model path: {args.model_path}")
    print(f"Evaluation output path: {args.evaluation_output}")

    main(args)

    mlflow.end_run()

================
File: amlws-assets/src/stageprep.py
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
"""
Prepares raw data and provides test dataset
"""

import argparse
from pathlib import Path
import pandas as pd
import mlflow

TARGET_COL = "cost"

NUMERIC_COLS = [
    "distance",
    "dropoff_latitude",
    "dropoff_longitude",
    "passengers",
    "pickup_latitude",
    "pickup_longitude",
    "pickup_weekday",
    "pickup_month",
    "pickup_monthday",
    "pickup_hour",
    "pickup_minute",
    "pickup_second",
    "dropoff_weekday",
    "dropoff_month",
    "dropoff_monthday",
    "dropoff_hour",
    "dropoff_minute",
    "dropoff_second",
]

CAT_NOM_COLS = [
    "store_forward",
    "vendor",
]

CAT_ORD_COLS = []

def parse_args():
    '''Parse input arguments'''

    parser = argparse.ArgumentParser("prep")
    parser.add_argument("--raw_data", type=str, help="Path to raw data")
    parser.add_argument("--test_data", type=str, help="Path to test dataset")
    parser.add_argument("--enable_monitoring", type=str, help="enable logging to ADX")
    parser.add_argument("--table_name", type=str, default="mlmonitoring", help="Table name in ADX for logging")

    args = parser.parse_args()

    return args

def log_test_data(df, table_name):
    from obs.collector import Online_Collector
    collector = Online_Collector(table_name)
    collector.batch_collect(df)

def main(args):
    '''Read and save test dataset'''

    # ------------ Reading Data ------------ #
    # -------------------------------------- #

    data = pd.read_csv(Path(args.raw_data))
    data = data[NUMERIC_COLS + CAT_NOM_COLS + CAT_ORD_COLS + [TARGET_COL]]

    # ------------- Save Test Data ------------- #
    # ------------------------------------------ #

    mlflow.log_metric('test size', data.shape[0])

    data.to_parquet((Path(args.test_data) / "test.parquet"))

    if args.enable_monitoring.lower() == 'true' or args.enable_monitoring == '1' or args.enable_monitoring.lower() == 'yes':
        log_test_data(data, args.table_name)

if __name__ == "__main__":

    mlflow.start_run()

    # ---------- Parse Arguments ----------- #
    # -------------------------------------- #

    args = parse_args()

    lines = [
        f"Raw data path: {args.raw_data}",
        f"Test dataset output path: {args.test_data}",
    ]

    for line in lines:
        print(line)

    main(args)

    mlflow.end_run()

================
File: amlws-assets/src/train.py
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
"""
Trains ML model using AutoML and training dataset. Saves trained model using MLflow pyfunc.
"""

import argparse
from pathlib import Path
import pandas as pd
from azureml.core import Run
from azureml.train.automl import AutoMLConfig
import mlflow
import mlflow.pyfunc
from mlflow.models.signature import infer_signature

class WrappedModel(mlflow.pyfunc.PythonModel):
    def __init__(self, model):
        self.model = model

    def predict(self, context, model_input):
        return self.model.predict(model_input)

def parse_args():
    '''Parse input arguments'''
    parser = argparse.ArgumentParser("train")
    parser.add_argument("--train_data", type=str, help="Path to train dataset")
    parser.add_argument("--model_output", type=str, help="Path of output model")
    parser.add_argument("--modelname", type=str, help="model name")
    args = parser.parse_args()
    return args

def main(args):
    # Get the experiment run context
    run = Run.get_context()

    # Load the training data
    train_data = pd.read_parquet(Path(args.train_data))

    # Split the data into inputs and outputs
    y_train = train_data['cost']
    X_train = train_data.drop('cost', axis=1)

    # Configure AutoML
    automl_config = AutoMLConfig(
        task='regression',
        primary_metric='r2_score',
        training_data=train_data,
        label_column_name='cost',
        n_cross_validations=5,
        enable_early_stopping=True,
        experiment_timeout_minutes=15,
        max_concurrent_iterations=4,
        max_cores_per_iteration=-1,
        enable_onnx_compatible_models=False,
        blocked_models=['TensorFlowDNN', 'TensorFlowLinearRegressor'],
        allowed_models=[
            'RandomForest', 'LightGBM', 'DecisionTree',
            'ElasticNet', 'GradientBoosting', 'KNN',
            'FastLinearRegressor', 'LassoLars', 'SGDRegressor', 'ExtraTreesRegressor'
        ]
    )

    # Submit the AutoML experiment
    automl_run = run.submit_child(automl_config, show_output=True)

    # Wait for the run to complete
    automl_run.wait_for_completion(show_output=True)

    # Get the best model
    best_run, fitted_model = automl_run.get_output()

    # Wrap the model
    wrapped_model = WrappedModel(fitted_model)

    # Infer the model signature
    signature = infer_signature(X_train, fitted_model.predict(X_train))


    # Save the model to the specified output path
    mlflow.pyfunc.save_model(
        path=args.model_output,
        python_model=wrapped_model,
        signature=signature
    )

    # Log metrics
    metrics = automl_run.get_metrics()
    for metric_name, metric_value in metrics.items():
        mlflow.log_metric(metric_name, metric_value)

    print(f"Best model saved to {args.model_output}")

if __name__ == "__main__":
    mlflow.start_run()
    args = parse_args()
    main(args)
    mlflow.end_run()

================
File: amlws-assets/src/train2.py
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
"""
Trains ML model using training dataset. Saves trained model.
"""

import argparse

from pathlib import Path

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

import mlflow
import mlflow.sklearn

TARGET_COL = "cost"

NUMERIC_COLS = [
    "distance",
    "dropoff_latitude",
    "dropoff_longitude",
    "passengers",
    "pickup_latitude",
    "pickup_longitude",
    "pickup_weekday",
    "pickup_month",
    "pickup_monthday",
    "pickup_hour",
    "pickup_minute",
    "pickup_second",
    "dropoff_weekday",
    "dropoff_month",
    "dropoff_monthday",
    "dropoff_hour",
    "dropoff_minute",
    "dropoff_second",
]

CAT_NOM_COLS = [
    "store_forward",
    "vendor",
]

CAT_ORD_COLS = [
]


def parse_args():
    '''Parse input arguments'''

    parser = argparse.ArgumentParser("train")
    parser.add_argument("--train_data", type=str, help="Path to train dataset")
    parser.add_argument("--model_output", type=str, help="Path of output model")

    # classifier specific arguments
    parser.add_argument('--regressor__n_estimators', type=int, default=500,
                        help='Number of trees')
    parser.add_argument('--regressor__bootstrap', type=bool, default=True,
                        help='Method of selecting samples for training each tree')
    parser.add_argument('--regressor__max_depth', type=int, default=10,
                        help=' Maximum number of levels in tree')
    parser.add_argument('--regressor__max_features', type=str, default='sqrt',
                        help='Number of features to consider at every split')
    parser.add_argument('--regressor__min_samples_leaf', type=int, default=4,
                        help='Minimum number of samples required at each leaf node')
    parser.add_argument('--regressor__min_samples_split', type=int, default=5,
                        help='Minimum number of samples required to split a node')

    args = parser.parse_args()

    return args

def main(args):
    '''Read train dataset, train model, save trained model'''

    # Read train data
    train_data = pd.read_parquet(Path(args.train_data))

    # Split the data into input(X) and output(y)
    y_train = train_data[TARGET_COL]
    X_train = train_data[NUMERIC_COLS + CAT_NOM_COLS + CAT_ORD_COLS]

    # Train a Random Forest Regression Model with the training set
    model = RandomForestRegressor(n_estimators = args.regressor__n_estimators,
                                  bootstrap = args.regressor__bootstrap,
                                  max_depth = args.regressor__max_depth,
                                  max_features = args.regressor__max_features,
                                  min_samples_leaf = args.regressor__min_samples_leaf,
                                  min_samples_split = args.regressor__min_samples_split,
                                  random_state=0)

    # log model hyperparameters
    mlflow.log_param("model", "RandomForestRegressor")
    mlflow.log_param("n_estimators", args.regressor__n_estimators)
    mlflow.log_param("bootstrap", args.regressor__bootstrap)
    mlflow.log_param("max_depth", args.regressor__max_depth)
    mlflow.log_param("max_features", args.regressor__max_features)
    mlflow.log_param("min_samples_leaf", args.regressor__min_samples_leaf)
    mlflow.log_param("min_samples_split", args.regressor__min_samples_split)

    # Train model with the train set
    model.fit(X_train, y_train)

    # Predict using the Regression Model
    yhat_train = model.predict(X_train)

    # Evaluate Regression performance with the train set
    r2 = r2_score(y_train, yhat_train)
    mse = mean_squared_error(y_train, yhat_train)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_train, yhat_train)
    
    # log model performance metrics
    mlflow.log_metric("train r2", r2)
    mlflow.log_metric("train mse", mse)
    mlflow.log_metric("train rmse", rmse)
    mlflow.log_metric("train mae", mae)

    # Visualize results
    plt.scatter(y_train, yhat_train,  color='black')
    plt.plot(y_train, y_train, color='blue', linewidth=3)
    plt.xlabel("Real value")
    plt.ylabel("Predicted value")
    plt.savefig("regression_results.png")
    mlflow.log_artifact("regression_results.png")

    # Save the model
    mlflow.sklearn.save_model(sk_model=model, path=args.model_output)


if __name__ == "__main__":
    
    mlflow.start_run()

    # ---------- Parse Arguments ----------- #
    # -------------------------------------- #

    args = parse_args()

    lines = [
        f"Train dataset input path: {args.train_data}",
        f"Model output path: {args.model_output}",
        f"n_estimators: {args.regressor__n_estimators}",
        f"bootstrap: {args.regressor__bootstrap}",
        f"max_depth: {args.regressor__max_depth}",
        f"max_features: {args.regressor__max_features}",
        f"min_samples_leaf: {args.regressor__min_samples_leaf}",
        f"min_samples_split: {args.regressor__min_samples_split}"
    ]

    for line in lines:
        print(line)

    main(args)

    mlflow.end_run()

================
File: infrastructure/env-variables/config-infra-dev.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

# Dev environment
variables:
  # Global
  ap_vm_image: ubuntu-20.04

  namespace: mlopsv2 #Note: A namespace with many characters will cause storage account creation to fail due to storage account names having a limit of 24 characters.
  postfix: 0001
  location: uksouth
  environment: dev
  enable_aml_computecluster: true
  enable_monitoring: false
  ds_data: $(Build.SourcesDirectory)/amlws-assets/data/data.yml
  ds_environment: automl
  pipeline_file: $(Build.SourcesDirectory)/amlws-assets/pipelinejobs/dev-train.yml
  virtual_environment: azure

  # Azure DevOps
  ado_service_connection_rg: Azure-ARM-Dev
  ado_service_connection_aml_ws: Azure-ARM-Dev

  # DO NOT TOUCH

  # For pipeline reference
  resource_group: rg-$(namespace)-$(postfix)$(environment)
  aml_workspace: mlw-$(namespace)-$(postfix)$(environment)
  application_insights: mlw-$(namespace)-$(postfix)$(environment)
  key_vault: kv-$(namespace)-$(postfix)$(environment)
  container_registry: cr$(namespace)$(postfix)$(environment)
  storage_account: st$(namespace)$(postfix)$(environment)

  # For terraform reference
  terraform_version: 1.3.6
  terraform_workingdir: infrastructure
  terraform_st_location: $(location)
  terraform_st_resource_group: rg-$(namespace)-$(postfix)$(environment)-tf
  terraform_st_storage_account: st$(namespace)$(postfix)$(environment)tf
  terraform_st_container_name: default
  terraform_st_key: mlops-tab

================
File: infrastructure/env-variables/config-infra-prod.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

# Prod environment
variables:
  # Global
  ap_vm_image: ubuntu-20.04

  namespace: mlopsv2 #Note: A namespace with many characters will cause storage account creation to fail due to storage account names having a limit of 24 characters.
  postfix: 0001
  location: uksouth
  environment: prod
  enable_aml_computecluster: true
  enable_monitoring: false
  virtual_environment: azure
  ds_environment: automl

  # Azure DevOps
  ado_service_connection_rg: Azure-ARM-Prod
  ado_service_connection_aml_ws: Azure-ARM-Prod

  # DO NOT TOUCH

  # For pipeline reference
  resource_group: rg-$(namespace)-$(postfix)$(environment)
  aml_workspace: mlw-$(namespace)-$(postfix)$(environment)
  application_insights: mlw-$(namespace)-$(postfix)$(environment)
  key_vault: kv-$(namespace)-$(postfix)$(environment)
  container_registry: cr$(namespace)$(postfix)$(environment)
  storage_account: st$(namespace)$(postfix)$(environment)

  # For terraform reference
  terraform_version: 1.3.6
  terraform_workingdir: infrastructure
  terraform_st_location: $(location)
  terraform_st_resource_group: rg-$(namespace)-$(postfix)$(environment)-tf
  terraform_st_storage_account: st$(namespace)$(postfix)$(environment)tf
  terraform_st_container_name: default
  terraform_st_key: mlops-tab

================
File: infrastructure/env-variables/config-infra-stage.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

# Prod environment
variables:
  # Global
  ap_vm_image: ubuntu-20.04

  namespace: mlopsv2 #Note: A namespace with many characters will cause storage account creation to fail due to storage account names having a limit of 24 characters.
  postfix: 0001
  location: uksouth
  environment: stage
  enable_aml_computecluster: true
  enable_monitoring: false
  ds_data: $(Build.SourcesDirectory)/amlws-assets/data/stage.yml
  ds_environment: automl
  pipeline_file: $(Build.SourcesDirectory)/amlws-assets/pipelinejobs/stage-test.yml
  virtual_environment: azure
  modelname: automl


  # Azure DevOps
  ado_service_connection_rg: Azure-ARM-Stage
  ado_service_connection_aml_ws: Azure-ARM-Stage

  # DO NOT TOUCH

  # For pipeline reference
  resource_group: rg-$(namespace)-$(postfix)$(environment)
  aml_workspace: mlw-$(namespace)-$(postfix)$(environment)
  application_insights: mlw-$(namespace)-$(postfix)$(environment)
  key_vault: kv-$(namespace)-$(postfix)$(environment)
  container_registry: cr$(namespace)$(postfix)$(environment)
  storage_account: st$(namespace)$(postfix)$(environment)

  # For terraform reference
  terraform_version: 1.3.6
  terraform_workingdir: infrastructure
  terraform_st_location: $(location)
  terraform_st_resource_group: rg-$(namespace)-$(postfix)$(environment)-tf
  terraform_st_storage_account: st$(namespace)$(postfix)$(environment)tf
  terraform_st_container_name: default
  terraform_st_key: mlops-tab

================
File: infrastructure/modules/aml_computecluster.bicep
================
param location string
param computeClusterName string = 'cpu-cluster'
param workspaceName string

resource amlci 'Microsoft.MachineLearningServices/workspaces/computes@2020-09-01-preview' = {
  name: '${workspaceName}/${computeClusterName}'
  location: location
  properties: {
    computeType: 'AmlCompute'
    properties: {
      vmSize: 'Standard_DS3_v2'
      subnet: json('null')
      osType: 'Linux'
      scaleSettings: {
        maxNodeCount: 4
        minNodeCount: 0
      }
    }
  }
}

================
File: infrastructure/modules/aml_workspace.bicep
================
param baseName string
param location string
param stoacctid string
param kvid string
param appinsightid string
param crid string
param tags object

// AML workspace
resource amls 'Microsoft.MachineLearningServices/workspaces@2020-09-01-preview' = {
  name: 'mlw-${baseName}'
  location: location
  identity: {
    type: 'SystemAssigned'
  }
  sku: {
    tier: 'basic'
    name: 'basic'
  }
  properties: {
    storageAccount: stoacctid
    keyVault: kvid
    applicationInsights: appinsightid
    containerRegistry: crid
    encryption: {
      status: 'Disabled'
      keyVaultProperties: {
        keyIdentifier: ''
        keyVaultArmId: ''
      }
    }
  }

  tags: tags
}

output amlsName string = amls.name

================
File: infrastructure/modules/application_insights.bicep
================
param baseName string
param location string
param tags object

// App Insights
resource appinsight 'Microsoft.Insights/components@2020-02-02-preview' = {
  name: 'appi-${baseName}'
  location: location
  kind: 'web'
  properties: {
    Application_Type: 'web'
  }

  tags: tags
}

output appinsightOut string = appinsight.id

================
File: infrastructure/modules/container_registry.bicep
================
param baseName string
param location string
param tags object

resource cr 'Microsoft.ContainerRegistry/registries@2020-11-01-preview' = {
  name: 'cr${baseName}'
  location: location
  sku: {
    name: 'Standard'
  }

  properties: {
    adminUserEnabled: true
  }

  tags: tags
}

output crOut string = cr.id

================
File: infrastructure/modules/key_vault.bicep
================
param baseName string
param location string
param tags object

// Key Vault
resource kv 'Microsoft.KeyVault/vaults@2019-09-01' = {
  name: 'kv-${baseName}'
  location: location
  properties: {
    tenantId: subscription().tenantId
    sku: {
      name: 'standard'
      family: 'A'
    }
    accessPolicies: []
  }

  tags: tags
}

output kvOut string = kv.id

================
File: infrastructure/modules/storage_account.bicep
================
param baseName string
param location string
param tags object

// Storage Account
resource stoacct 'Microsoft.Storage/storageAccounts@2019-04-01' = {
  name: 'st${baseName}'
  location: location
  sku: {
    name: 'Standard_LRS'
  }
  kind: 'StorageV2'
  properties: {
    encryption: {
      services: {
        blob: {
          enabled: true
        }
        file: {
          enabled: true
        }
      }
      keySource: 'Microsoft.Storage'
    }
    supportsHttpsTrafficOnly: true
  }

  tags: tags
}

output stoacctOut string = stoacct.id

================
File: infrastructure/pipelines/bicep-ado-deploy-infra.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

name: bicep-ado-deploy-infra

variables:
  - ${{ if eq(variables['Build.SourceBranchName'], 'main') }}:
      # 'main' branch: PRD environment
      - template: ../../infrastructure/env-variables/config-infra-pod.yml
  - ${{ if eq(variables['Build.SourceBranchName'], 'staging') }}:
      # 'staging' branch: STAGE environment
      - template: ../../infrastructure/env-variables/config-infra-stage.yml
  - ${{ if eq(variables['Build.SourceBranchName'], 'develop') }}:
      # 'develop' branch: DEV environment
      - template: ../../infrastructure/env-variables/config-infra-dev.yml

trigger: none

pool:
  name: Default

stages:
  - stage: Lint
    displayName: Lint and Preflight check
    jobs:
      - job: LintBicep
        displayName: Lint Bicep Code
        steps:
          - checkout: self
          - script: |
              az bicep build --file ./infrastructure/main.bicep
            name: LintBicepCode
            displayName: Run Bicep Linter

  - stage: PreflightValidation
    jobs:
      - job: ValidateBicepCode
        displayName: Validate Bicep Code
        steps:
          - task: AzureCli@2
            name: RunPreflightValidateion
            displayName: Run Preflight Validation
            inputs:
              azureSubscription: $(ado_service_connection_rg)
              scriptType: "bash"
              scriptLocation: "inlineScript"
              inlineScript: |
                az deployment sub validate \
                  --name $(Build.DefinitionName) \
                  --template-file ./infrastructure/main.bicep \
                  --location $(location) \
                  --parameters location=$(location) prefix=$(namespace) postfix=$(postfix) env=$(environment)

  - stage: CheckOutBicepAndDeploy
    displayName: Deploy AML Workspace
    jobs:
      - deployment: DevDeployBicep
        displayName: Deploy Bicep
        pool:
          name: Default
        environment: $(environment)
        strategy:
          runOnce:
            deploy:
              steps:
                - checkout: self
                - task: AzureCLI@2
                  displayName: Running ${{ variables.environment }} Deployment
                  inputs:
                    azureSubscription: $(ado_service_connection_rg)
                    scriptType: bash
                    scriptLocation: inlineScript
                    inlineScript: |
                      az --version
                      echo "deploying bicep..."
                      az deployment sub create \
                        --name $(Build.DefinitionName) \
                        --location $(location) \
                        --template-file ./infrastructure/main.bicep \
                        --parameters location=$(location) prefix=$(namespace) postfix=$(postfix) env=$(environment)

================
File: infrastructure/bicepconfig.json
================
{
    "analyzers": {
      "core": {
        "enabled": true,
        "verbose": true,
        "rules": {
          "no-hardcoded-env-urls": {
            "level": "error"
          },
          "no-unused-params": {
            "level": "error"
          },
          "no-unused-vars": {
            "level": "error"
          },
          "prefer-interpolation": {
            "level": "error"
          },
          "secure-parameter-default": {
            "level": "error"
          },
          "simplify-interpolation": {
            "level": "error"
          }
        }
      }
    }
  }

================
File: infrastructure/main.bicep
================
targetScope = 'subscription'

param location string = 'westus2'
param prefix string
param postfix string
param env string 

param tags object = {
  Owner: 'tickops'
  Project: 'tickops'
  Environment: env
  Toolkit: 'bicep'
  Name: prefix
}

var baseName  = '${prefix}-${postfix}${env}'
var resourceGroupName = 'rg-${baseName}'

resource rg 'Microsoft.Resources/resourceGroups@2020-06-01' = {
  name: resourceGroupName
  location: location

  tags: tags
}

// Storage Account
module st './modules/storage_account.bicep' = {
  name: 'st'
  scope: resourceGroup(rg.name)
  params: {
    baseName: '${prefix}${postfix}${env}'
    location: location
    tags: tags
  }
}

// Key Vault
module kv './modules/key_vault.bicep' = {
  name: 'kv'
  scope: resourceGroup(rg.name)
  params: {
    baseName: baseName
    location: location
    tags: tags
  }
}

// App Insights
module appi './modules/application_insights.bicep' = {
  name: 'appi'
  scope: resourceGroup(rg.name)
  params: {
    baseName: baseName
    location: location
    tags: tags
  }
}

// Container Registry
module cr './modules/container_registry.bicep' = {
  name: 'cr'
  scope: resourceGroup(rg.name)
  params: {
    baseName: '${prefix}${postfix}${env}'
    location: location
    tags: tags
  }
}

// AML workspace
module mlw './modules/aml_workspace.bicep' = {
  name: 'mlw'
  scope: resourceGroup(rg.name)
  params: {
    baseName: baseName
    location: location
    stoacctid: st.outputs.stoacctOut
    kvid: kv.outputs.kvOut
    appinsightid: appi.outputs.appinsightOut
    crid: cr.outputs.crOut
    tags: tags
  }
}

// AML compute cluster
module mlwcc './modules/aml_computecluster.bicep' = {
  name: 'mlwcc'
  scope: resourceGroup(rg.name)
  params: {
    location: location
    workspaceName: mlw.outputs.amlsName
  }
}

================
File: infrastructure/main.json
================
{
  "$schema": "https://schema.management.azure.com/schemas/2018-05-01/subscriptionDeploymentTemplate.json#",
  "contentVersion": "1.0.0.0",
  "metadata": {
    "_generator": {
      "name": "bicep",
      "version": "0.5.6.12127",
      "templateHash": "11208633954998583577"
    }
  },
  "parameters": {
    "location": {
      "type": "string",
      "defaultValue": "westus2"
    },
    "env": {
      "type": "string",
      "defaultValue": "dev"
    },
    "prefix": {
      "type": "string"
    },
    "postfix": {
      "type": "string"
    },
    "resourceGroupName": {
      "type": "string",
      "defaultValue": "rg-wus-test"
    }
  },
  "variables": {
    "baseName": "[format('{0}{1}', parameters('prefix'), parameters('postfix'))]"
  },
  "resources": [
    {
      "type": "Microsoft.Resources/resourceGroups",
      "apiVersion": "2020-06-01",
      "name": "[parameters('resourceGroupName')]",
      "location": "[parameters('location')]"
    },
    {
      "type": "Microsoft.Resources/deployments",
      "apiVersion": "2020-10-01",
      "name": "stoacct",
      "resourceGroup": "[parameters('resourceGroupName')]",
      "properties": {
        "expressionEvaluationOptions": {
          "scope": "inner"
        },
        "mode": "Incremental",
        "parameters": {
          "env": {
            "value": "[parameters('env')]"
          },
          "baseName": {
            "value": "[variables('baseName')]"
          },
          "location": {
            "value": "[parameters('location')]"
          }
        },
        "template": {
          "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
          "contentVersion": "1.0.0.0",
          "metadata": {
            "_generator": {
              "name": "bicep",
              "version": "0.5.6.12127",
              "templateHash": "13854706444404712543"
            }
          },
          "parameters": {
            "env": {
              "type": "string"
            },
            "baseName": {
              "type": "string"
            },
            "location": {
              "type": "string"
            }
          },
          "resources": [
            {
              "type": "Microsoft.Storage/storageAccounts",
              "apiVersion": "2019-04-01",
              "name": "[format('{0}{1}sa', parameters('env'), parameters('baseName'))]",
              "location": "[parameters('location')]",
              "sku": {
                "name": "Standard_LRS"
              },
              "kind": "StorageV2",
              "properties": {
                "encryption": {
                  "services": {
                    "blob": {
                      "enabled": true
                    },
                    "file": {
                      "enabled": true
                    }
                  },
                  "keySource": "Microsoft.Storage"
                },
                "supportsHttpsTrafficOnly": true
              }
            }
          ],
          "outputs": {
            "stoacctOut": {
              "type": "string",
              "value": "[resourceId('Microsoft.Storage/storageAccounts', format('{0}{1}sa', parameters('env'), parameters('baseName')))]"
            }
          }
        }
      },
      "dependsOn": [
        "[subscriptionResourceId('Microsoft.Resources/resourceGroups', parameters('resourceGroupName'))]"
      ]
    },
    {
      "type": "Microsoft.Resources/deployments",
      "apiVersion": "2020-10-01",
      "name": "kv",
      "resourceGroup": "[parameters('resourceGroupName')]",
      "properties": {
        "expressionEvaluationOptions": {
          "scope": "inner"
        },
        "mode": "Incremental",
        "parameters": {
          "env": {
            "value": "[parameters('env')]"
          },
          "location": {
            "value": "[parameters('location')]"
          },
          "baseName": {
            "value": "[variables('baseName')]"
          }
        },
        "template": {
          "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
          "contentVersion": "1.0.0.0",
          "metadata": {
            "_generator": {
              "name": "bicep",
              "version": "0.5.6.12127",
              "templateHash": "3960831692549416869"
            }
          },
          "parameters": {
            "baseName": {
              "type": "string"
            },
            "env": {
              "type": "string"
            },
            "location": {
              "type": "string"
            }
          },
          "resources": [
            {
              "type": "Microsoft.KeyVault/vaults",
              "apiVersion": "2019-09-01",
              "name": "[format('{0}-{1}-kv', parameters('env'), parameters('baseName'))]",
              "location": "[parameters('location')]",
              "properties": {
                "tenantId": "[subscription().tenantId]",
                "sku": {
                  "name": "standard",
                  "family": "A"
                },
                "accessPolicies": []
              }
            }
          ],
          "outputs": {
            "kvOut": {
              "type": "string",
              "value": "[resourceId('Microsoft.KeyVault/vaults', format('{0}-{1}-kv', parameters('env'), parameters('baseName')))]"
            }
          }
        }
      },
      "dependsOn": [
        "[subscriptionResourceId('Microsoft.Resources/resourceGroups', parameters('resourceGroupName'))]"
      ]
    },
    {
      "type": "Microsoft.Resources/deployments",
      "apiVersion": "2020-10-01",
      "name": "appinsight",
      "resourceGroup": "[parameters('resourceGroupName')]",
      "properties": {
        "expressionEvaluationOptions": {
          "scope": "inner"
        },
        "mode": "Incremental",
        "parameters": {
          "baseName": {
            "value": "[variables('baseName')]"
          },
          "env": {
            "value": "[parameters('env')]"
          },
          "location": {
            "value": "[parameters('location')]"
          }
        },
        "template": {
          "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
          "contentVersion": "1.0.0.0",
          "metadata": {
            "_generator": {
              "name": "bicep",
              "version": "0.5.6.12127",
              "templateHash": "2591061638125956638"
            }
          },
          "parameters": {
            "baseName": {
              "type": "string"
            },
            "env": {
              "type": "string"
            },
            "location": {
              "type": "string"
            }
          },
          "resources": [
            {
              "type": "Microsoft.Insights/components",
              "apiVersion": "2020-02-02-preview",
              "name": "[format('{0}{1}-appin', parameters('env'), parameters('baseName'))]",
              "location": "[parameters('location')]",
              "kind": "web",
              "properties": {
                "Application_Type": "web"
              }
            }
          ],
          "outputs": {
            "appinsightOut": {
              "type": "string",
              "value": "[resourceId('Microsoft.Insights/components', format('{0}{1}-appin', parameters('env'), parameters('baseName')))]"
            }
          }
        }
      },
      "dependsOn": [
        "[subscriptionResourceId('Microsoft.Resources/resourceGroups', parameters('resourceGroupName'))]"
      ]
    },
    {
      "type": "Microsoft.Resources/deployments",
      "apiVersion": "2020-10-01",
      "name": "cr",
      "resourceGroup": "[parameters('resourceGroupName')]",
      "properties": {
        "expressionEvaluationOptions": {
          "scope": "inner"
        },
        "mode": "Incremental",
        "parameters": {
          "baseName": {
            "value": "[variables('baseName')]"
          },
          "env": {
            "value": "[parameters('env')]"
          },
          "location": {
            "value": "[parameters('location')]"
          }
        },
        "template": {
          "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
          "contentVersion": "1.0.0.0",
          "metadata": {
            "_generator": {
              "name": "bicep",
              "version": "0.5.6.12127",
              "templateHash": "12155558635582316098"
            }
          },
          "parameters": {
            "env": {
              "type": "string"
            },
            "baseName": {
              "type": "string"
            },
            "location": {
              "type": "string"
            }
          },
          "resources": [
            {
              "type": "Microsoft.ContainerRegistry/registries",
              "apiVersion": "2020-11-01-preview",
              "name": "[format('{0}{1}cr', parameters('env'), parameters('baseName'))]",
              "location": "[parameters('location')]",
              "sku": {
                "name": "Standard"
              },
              "properties": {
                "adminUserEnabled": true
              }
            }
          ],
          "outputs": {
            "crOut": {
              "type": "string",
              "value": "[resourceId('Microsoft.ContainerRegistry/registries', format('{0}{1}cr', parameters('env'), parameters('baseName')))]"
            }
          }
        }
      },
      "dependsOn": [
        "[subscriptionResourceId('Microsoft.Resources/resourceGroups', parameters('resourceGroupName'))]"
      ]
    },
    {
      "type": "Microsoft.Resources/deployments",
      "apiVersion": "2020-10-01",
      "name": "amls",
      "resourceGroup": "[parameters('resourceGroupName')]",
      "properties": {
        "expressionEvaluationOptions": {
          "scope": "inner"
        },
        "mode": "Incremental",
        "parameters": {
          "baseName": {
            "value": "[variables('baseName')]"
          },
          "env": {
            "value": "[parameters('env')]"
          },
          "location": {
            "value": "[parameters('location')]"
          },
          "stoacctid": {
            "value": "[reference(extensionResourceId(format('/subscriptions/{0}/resourceGroups/{1}', subscription().subscriptionId, parameters('resourceGroupName')), 'Microsoft.Resources/deployments', 'stoacct')).outputs.stoacctOut.value]"
          },
          "kvid": {
            "value": "[reference(extensionResourceId(format('/subscriptions/{0}/resourceGroups/{1}', subscription().subscriptionId, parameters('resourceGroupName')), 'Microsoft.Resources/deployments', 'kv')).outputs.kvOut.value]"
          },
          "appinsightid": {
            "value": "[reference(extensionResourceId(format('/subscriptions/{0}/resourceGroups/{1}', subscription().subscriptionId, parameters('resourceGroupName')), 'Microsoft.Resources/deployments', 'appinsight')).outputs.appinsightOut.value]"
          },
          "crid": {
            "value": "[reference(extensionResourceId(format('/subscriptions/{0}/resourceGroups/{1}', subscription().subscriptionId, parameters('resourceGroupName')), 'Microsoft.Resources/deployments', 'cr')).outputs.crOut.value]"
          }
        },
        "template": {
          "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
          "contentVersion": "1.0.0.0",
          "metadata": {
            "_generator": {
              "name": "bicep",
              "version": "0.5.6.12127",
              "templateHash": "18023230433604735324"
            }
          },
          "parameters": {
            "location": {
              "type": "string"
            },
            "baseName": {
              "type": "string"
            },
            "env": {
              "type": "string"
            },
            "stoacctid": {
              "type": "string"
            },
            "kvid": {
              "type": "string"
            },
            "appinsightid": {
              "type": "string"
            },
            "crid": {
              "type": "string"
            }
          },
          "resources": [
            {
              "type": "Microsoft.MachineLearningServices/workspaces",
              "apiVersion": "2020-09-01-preview",
              "name": "[format('{0}{1}-ws', parameters('env'), parameters('baseName'))]",
              "location": "[parameters('location')]",
              "identity": {
                "type": "SystemAssigned"
              },
              "sku": {
                "tier": "basic",
                "name": "basic"
              },
              "properties": {
                "friendlyName": "[format('{0}{1}-ws', parameters('env'), parameters('baseName'))]",
                "storageAccount": "[parameters('stoacctid')]",
                "keyVault": "[parameters('kvid')]",
                "applicationInsights": "[parameters('appinsightid')]",
                "containerRegistry": "[parameters('crid')]",
                "encryption": {
                  "status": "Disabled",
                  "keyVaultProperties": {
                    "keyIdentifier": "",
                    "keyVaultArmId": ""
                  }
                }
              }
            }
          ],
          "outputs": {
            "amlsName": {
              "type": "string",
              "value": "[format('{0}{1}-ws', parameters('env'), parameters('baseName'))]"
            }
          }
        }
      },
      "dependsOn": [
        "[extensionResourceId(format('/subscriptions/{0}/resourceGroups/{1}', subscription().subscriptionId, parameters('resourceGroupName')), 'Microsoft.Resources/deployments', 'appinsight')]",
        "[extensionResourceId(format('/subscriptions/{0}/resourceGroups/{1}', subscription().subscriptionId, parameters('resourceGroupName')), 'Microsoft.Resources/deployments', 'cr')]",
        "[extensionResourceId(format('/subscriptions/{0}/resourceGroups/{1}', subscription().subscriptionId, parameters('resourceGroupName')), 'Microsoft.Resources/deployments', 'kv')]",
        "[subscriptionResourceId('Microsoft.Resources/resourceGroups', parameters('resourceGroupName'))]",
        "[extensionResourceId(format('/subscriptions/{0}/resourceGroups/{1}', subscription().subscriptionId, parameters('resourceGroupName')), 'Microsoft.Resources/deployments', 'stoacct')]"
      ]
    },
    {
      "type": "Microsoft.Resources/deployments",
      "apiVersion": "2020-10-01",
      "name": "amlci",
      "resourceGroup": "[parameters('resourceGroupName')]",
      "properties": {
        "expressionEvaluationOptions": {
          "scope": "inner"
        },
        "mode": "Incremental",
        "parameters": {
          "baseName": {
            "value": "[variables('baseName')]"
          },
          "env": {
            "value": "[parameters('env')]"
          },
          "location": {
            "value": "[parameters('location')]"
          },
          "workspaceName": {
            "value": "[reference(extensionResourceId(format('/subscriptions/{0}/resourceGroups/{1}', subscription().subscriptionId, parameters('resourceGroupName')), 'Microsoft.Resources/deployments', 'amls')).outputs.amlsName.value]"
          }
        },
        "template": {
          "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
          "contentVersion": "1.0.0.0",
          "metadata": {
            "_generator": {
              "name": "bicep",
              "version": "0.5.6.12127",
              "templateHash": "2016431671585526523"
            }
          },
          "parameters": {
            "location": {
              "type": "string"
            },
            "baseName": {
              "type": "string"
            },
            "env": {
              "type": "string"
            },
            "computeInstanceName": {
              "type": "string",
              "defaultValue": "[format('{0}-{1}-ci', parameters('env'), parameters('baseName'))]"
            },
            "workspaceName": {
              "type": "string"
            }
          },
          "resources": [
            {
              "type": "Microsoft.MachineLearningServices/workspaces/computes",
              "apiVersion": "2020-09-01-preview",
              "name": "[format('{0}/{1}', parameters('workspaceName'), parameters('computeInstanceName'))]",
              "location": "[parameters('location')]",
              "properties": {
                "computeType": "AmlCompute",
                "properties": {
                  "vmSize": "Standard_DS3_v2",
                  "subnet": "[json('null')]",
                  "osType": "Linux",
                  "scaleSettings": {
                    "maxNodeCount": 4,
                    "minNodeCount": 0
                  }
                }
              }
            }
          ]
        }
      },
      "dependsOn": [
        "[extensionResourceId(format('/subscriptions/{0}/resourceGroups/{1}', subscription().subscriptionId, parameters('resourceGroupName')), 'Microsoft.Resources/deployments', 'amls')]",
        "[subscriptionResourceId('Microsoft.Resources/resourceGroups', parameters('resourceGroupName'))]"
      ]
    }
  ]
}

================
File: mlops-ado-pipelines/dev-model-training.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. Test 1 G

name: dev-model-training

variables:
  - template: ../infrastructure/env-variables/config-infra-dev.yml

trigger: none

pool:
  name: Default

stages:
  - stage: TrainModelInDev
    displayName: Train Model in Dev Environment
    jobs:
      - job: TrainModel
        timeoutInMinutes: 120
        steps:
          - template: ../ado-aml-cli-v2-templates/install-az-cli.yml
          - template: ../ado-aml-cli-v2-templates/install-aml-cli.yml
          - template: ../ado-aml-cli-v2-templates/connect-to-workspace.yml
          - template: ../ado-aml-cli-v2-templates/register-environment.yml
            parameters:
              environment_name: $(ds_environment)-env
              environment_file: $(Build.SourcesDirectory)/amlws-assets/environment/$(ds_environment)-env.yml
          - template: ../ado-aml-cli-v2-templates/create-compute.yml
            parameters:
              cluster_name: cpu-cluster
              size: Standard_DS3_v2
              min_instances: 0
              max_instances: 4
              cluster_tier: low_priority
          - template: ../ado-aml-cli-v2-templates/register-data.yml
            parameters:
              data_type: uri_file
              data_name: data
              data_file: $(ds_data)

          - template: ../ado-aml-cli-v2-templates/run-pipeline.yml
            parameters:
              pipeline_file: $(pipeline_file)
              experiment_name: dev_$(Build.Repository.Name)_train_$(Build.SourceBranchName)
              display_name: dev_$(Build.Repository.Name)_run_$(Build.BuildID)
              enable_monitoring: $(enable_monitoring)
              modelname: ${{ variables.modelname }}

================
File: mlops-ado-pipelines/prod-batch-endpoint.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

name: batch-endpoint

variables:
  - template: ../../infrastructure/env-variables/config-infra-prod.yml
  - name: version
    value: ado-aml-cli-v2-templates
  - name: endpoint_name
    value: $(Build.Repository.Name)-batch-$(namespace)$(postfix)$(environment)
  - name: endpoint_type
    value: batch

trigger: none

pool:
  name: Default

stages:
  - stage: CreateBatchEndpoint
    displayName: Create/Update Batch Endpoint
    jobs:
      - job: DeployBatchEndpoint
        steps:
          - template: ../ado-aml-cli-v2-templates/install-az-cli.yml
          - template: ../ado-aml-cli-v2-templates/install-aml-cli.yml
          - template: ../ado-aml-cli-v2-templates/connect-to-workspace.yml
          - template: ../ado-aml-cli-v2-templates/create-compute.yml
            parameters:
              cluster_name: batch-cluster # name must match cluster name in deployment file below
              size: STANDARD_DS3_V2
              min_instances: 0
              max_instances: 5
              cluster_tier: dedicated
          - template: ../ado-aml-cli-v2-templates/create-endpoint.yml
            parameters:
              endpoint_file: $(Build.SourcesDirectory)/amlws-assets/endpoints/batch/batch-endpoint.yml
          - template: ../ado-aml-cli-v2-templates/create-deployment.yml
            parameters:
              deployment_name: $(Build.Repository.Name)-batch-dp
              deployment_file: $(Build.SourcesDirectory)/amlws-assets/endpoints/batch/batch-deployment.yml
          - template: ../ado-aml-cli-v2-templates/test-deployment.yml
            parameters:
              deployment_name: $(Build.Repository.Name)-batch-dp
              sample_request: $(Build.SourcesDirectory)/amlws-assets/data/batch.csv
              request_type: uri_file #either uri_folder or uri_file

================
File: mlops-ado-pipelines/prod-onine-endpoint.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

name: online-endpoint

variables:
  - template: ../infrastructure/env-variables/config-infra-prod.yml
  - name: endpoint_name
    value: $(Build.Repository.Name)-online-$(environment)-$(Build.BuildID)
  - name: deployment_name
    value: $(Build.Repository.Name)-online-$(environment)-$(Build.BuildID)-dp
  - name: endpoint_type
    value: online

trigger: none

pool:
  name: Default

stages:
  - stage: CreateOnlineEndpoint
    displayName: Create/Update Online Endpoint
    jobs:
      - job: DeployOnlineEndpoint
        steps:
          - template: ../ado-aml-cli-v2-templates/install-az-cli.yml
          - template: ../ado-aml-cli-v2-templates/install-aml-cli.yml
          - template: ../ado-aml-cli-v2-templates/connect-to-workspace.yml
          - template: ../ado-aml-cli-v2-templates/create-endpoint.yml
            parameters:
              endpoint_file: $(Build.SourcesDirectory)/amlws-assets/endpoints/online/online-endpoint.yml
          - template: ../ado-aml-cli-v2-templates/create-deployment.yml
            parameters:
              deployment_name: $(Build.Repository.Name)-online-dp
              deployment_file: $(Build.SourcesDirectory)/amlws-assets/endpoints/online/online-deployment.yml
          - template: ../ado-aml-cli-v2-templates/allocate-traffic.yml
            parameters:
              traffic_allocation: $(Build.Repository.Name)-online-dp=100
          - template: ../ado-aml-cli-v2-templates/test-deployment.yml
            parameters:
              deployment_name: $(Build.Repository.Name)-online-dp
              sample_request: $(Build.SourcesDirectory)/amlws-assets/data/request.json
              request_type: json

================
File: mlops-ado-pipelines/prod-register-in-production.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

name: register-in-staging

variables:
  - template: ../infrastructure/env-variables/config-infra-dev.yml
  
trigger: none

pool:
  name: Default

stages:
  - stage: DownloadLatestModelFromStage
    displayName: Download Latest Model from Stage
    jobs:
      - job: DownloadModel
        steps:
          - task: AzureCLI@2
            displayName: Install AZ ML dependencies
            inputs:
              azureSubscription: 'Azure-ARM-Stage'
              scriptType: bash
              scriptLocation: inlineScript
              workingDirectory: $(System.DefaultWorkingDirectory)
              inlineScript: |
                set -e # fail on error
                
                # Check if the virtual environment exists, create if it doesn't
                if [ ! -d ~/myagent/$(virtual_environment) ]; then
                  echo "Creating virtual environment $(virtual_environment)"
                  python3 -m venv ~/myagent/$(virtual_environment)
                else
                  echo "Virtual environment $(virtual_environment) already exists"
                fi

                # Check if we're in the virtual environment, activate only if needed
                if [[ "$VIRTUAL_ENV" != */myagent/$(virtual_environment) ]]; then
                  echo "Activating $(virtual_environment) virtual environment"
                  source ~/myagent/$(virtual_environment)/bin/activate
                else
                  echo "Already in $(virtual_environment) virtual environment"
                fi
                
                echo "Python version: $(python --version)"
                echo "Pip version: $(pip --version)"

                # Upgrade pip, setuptools, and wheel
                python -m pip install --upgrade pip setuptools wheel
                # Install or upgrade azure-cli
                python -m pip install --upgrade azure-cli

                # Function to compare versions
                version_gt() { test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1"; }

                # Function to check and install package
                check_and_install() {
                  package=$1
                  required_version=$2
                  installed_version=$(pip show $package 2>/dev/null | grep Version | cut -d ' ' -f 2)
                  
                  if [ -z "$installed_version" ]; then
                    echo "Installing $package $required_version"
                    pip install "$package==$required_version"
                  elif version_gt $required_version $installed_version; then
                    echo "Updating $package from $installed_version to $required_version"
                    pip install --upgrade "$package==$required_version"
                  else
                    echo "$package is already at version $installed_version (required: $required_version)"
                  fi
                }

                # List of packages and their required versions
                packages="azure-ai-ml:1.1.0 azure-common:1.1.28 azure-core:1.26.1 azure-identity:1.10.0 azure-mgmt-core:1.3.0 azure-storage-blob:12.14.1 azure-storage-file-datalake:12.9.1 azure-storage-file-share:12.7.0"

                # Check and install packages if necessary
                echo "$packages" | tr ' ' '\n' | while IFS=':' read -r package version; do
                  check_and_install "$package" "$version"
                done

                # Update these packages to latest versions
                pip install --upgrade pyOpenSSL cryptography requests

                # Display Azure CLI version
                az version

                echo "Azure CLI and dependencies installation completed."

            env:
              PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)
          - task: AzureCLI@2
            displayName: Install AML CLI v2
            inputs:
              azureSubscription: 'Azure-ARM-Stage'
              scriptType: bash
              scriptLocation: inlineScript
              workingDirectory: $(System.DefaultWorkingDirectory)
              inlineScript: |
                set -e # fail on error
                
                # Check if we're in the virtual environment, activate only if needed
                if [[ "$VIRTUAL_ENV" != */myagent/$(virtual_environment) ]]; then
                  echo "Activating $(virtual_environment) virtual environment"
                  source ~/myagent/$(virtual_environment)/bin/activate
                else
                  echo "Already in $(virtual_environment) virtual environment"
                fi
                
                echo "Python version: $(python --version)"
                echo "Pip version: $(pip --version)"

                # Display Azure CLI version
                az version

                # Add and update the ml extension
                az extension  add -n ml

                # List all extensions
                az extension list

                echo "AML CLI v2 installation completed."

            env:
              PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)
              
          - task: AzureCLI@2
            displayName: Connect to AML Workspace using CLI v2
            inputs:
              azureSubscription: 'Azure-ARM-Stage'
              scriptType: bash
              scriptLocation: inlineScript
              inlineScript: |
                az configure --defaults group=rg-$(Build.Repository.Name)-0001stage workspace=mlw-$(Build.Repository.Name)-0001stage
                currentId=$(az account show -o tsv --query id | tr -d '"\r')
                echo "##vso[task.setvariable variable=subscription_id;]$currentId"
                JSON_STRING=$'{\n\t"subscription_id": "%s",\n\t"resource_group": "%s",\n\t"workspace_name": "%s"\n}'
                printf "$JSON_STRING" "$currentId" "rg-$(Build.Repository.Name)-0001stage" "mlw-$(Build.Repository.Name)-0001stage"
                printf "$JSON_STRING" "$currentId" "rg-$(Build.Repository.Name)-0001stage" "mlw-$(Build.Repository.Name)-0001stage" > config.json
          - task: AzureCLI@2
            displayName: 'Download Latest Model from Stage'
            inputs:
              azureSubscription: 'Azure-ARM-Stage'
              scriptType: 'bash'
              scriptLocation: 'inlineScript'
              inlineScript: |
                set -e # fail on error
                
                # Check if the virtual environment exists, create if it doesn't
                if [ ! -d ~/myagent/$(virtual_environment) ]; then
                  echo "Creating virtual environment $(virtual_environment)"
                  python3 -m venv ~/myagent/$(virtual_environment)
                else
                  echo "Virtual environment $(virtual_environment) already exists"
                fi
                # Check if we're in the virtual environment, activate only if needed
                if [[ "$VIRTUAL_ENV" != */myagent/$(virtual_environment) ]]; then
                  echo "Activating $(virtual_environment) virtual environment"
                  source ~/myagent/$(virtual_environment)/bin/activate
                else
                  echo "Already in $(virtual_environment) virtual environment"
                fi
                #!/bin/bash

                # Set the model name
                MODEL_NAME="$(ds_environment)-model"

                echo "Fetching the latest version of model: $MODEL_NAME"

                # Get the latest version of the model
                latest_version=$(az ml model list \
                    --resource-group rg-$(Build.Repository.Name)-0001stage \
                    --workspace-name mlw-$(Build.Repository.Name)-0001stage \
                    --name $MODEL_NAME \
                    --query "max_by([], &version).version" \
                    -o tsv)

                if [ -z "$latest_version" ]; then
                    echo "Error: Unable to fetch the latest version for model $MODEL_NAME"
                    exit 1
                fi

                echo "Latest version of $MODEL_NAME is: $latest_version"

                echo "Attempting to download the latest version of the model"

                az ml model download \
                    --resource-group rg-$(Build.Repository.Name)-0001stage \
                    --workspace-name mlw-$(Build.Repository.Name)-0001stage \
                    --name $MODEL_NAME \
                    --version $latest_version \
                    --download-path "$(Build.ArtifactStagingDirectory)/model"

                if [ $? -ne 0 ]; then
                    echo "Error: Failed to download the latest version of the model. Please check the model availability and permissions."
                    echo "Attempting to get more information about the model..."
                    
                    az ml model show \
                        --resource-group rg-$(Build.Repository.Name)-0001stage \
                        --workspace-name mlw-$(Build.Repository.Name)-0001stage \
                        --name $MODEL_NAME \
                        --version $latest_version

                    exit 1
                fi

                echo "Model downloaded successfully to: $(Build.ArtifactStagingDirectory)/model"
                echo "Contents of downloaded directory:"
                ls -R $(Build.ArtifactStagingDirectory)/model

                # Verify the downloaded model
                echo "Model details:"
                az ml model show \
                    --resource-group rg-$(Build.Repository.Name)-0001stage \
                    --workspace-name mlw-$(Build.Repository.Name)-0001stage \
                    --name $MODEL_NAME \
                    --version $latest_version
            env:
              PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

          - publish: $(Build.ArtifactStagingDirectory)/model
            artifact: latestTrainedModel
            displayName: 'Publish Latest Trained Model'

  - stage: RegisterModelInStaging
    displayName: Register Model in Staging Environment
    dependsOn: DownloadLatestModelFromStage
    jobs:
      - job: RegisterModel
        steps:
          - checkout: self
            path: s/
          - download: current
            artifact: latestTrainedModel
            displayName: 'Download Latest Trained Model'
          - task: Bash@3
            inputs:
              targetType: 'inline'
              script: |
                echo "Contents of $(Pipeline.Workspace)/latestTrainedModel:"
                ls -R $(Pipeline.Workspace)/latestTrainedModel
            displayName: 'Debug: List Downloaded Artifact Contents'
          - task: AzureCLI@2
            displayName: Install AZ ML dependencies
            inputs:
              azureSubscription: 'Azure-ARM-Prod'
              scriptType: bash
              scriptLocation: inlineScript
              workingDirectory: $(System.DefaultWorkingDirectory)
              inlineScript: |
                set -e # fail on error
                
                # Check if the virtual environment exists, create if it doesn't
                if [ ! -d ~/myagent/$(virtual_environment) ]; then
                  echo "Creating virtual environment $(virtual_environment)"
                  python3 -m venv ~/myagent/$(virtual_environment)
                else
                  echo "Virtual environment $(virtual_environment) already exists"
                fi

                # Check if we're in the virtual environment, activate only if needed
                if [[ "$VIRTUAL_ENV" != */myagent/$(virtual_environment) ]]; then
                  echo "Activating $(virtual_environment) virtual environment"
                  source ~/myagent/$(virtual_environment)/bin/activate
                else
                  echo "Already in $(virtual_environment) virtual environment"
                fi
                
                echo "Python version: $(python --version)"
                echo "Pip version: $(pip --version)"

                # Upgrade pip, setuptools, and wheel
                python -m pip install --upgrade pip setuptools wheel
                # Install or upgrade azure-cli
                python -m pip install --upgrade azure-cli

                # Function to compare versions
                version_gt() { test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1"; }

                # Function to check and install package
                check_and_install() {
                  package=$1
                  required_version=$2
                  installed_version=$(pip show $package 2>/dev/null | grep Version | cut -d ' ' -f 2)
                  
                  if [ -z "$installed_version" ]; then
                    echo "Installing $package $required_version"
                    pip install "$package==$required_version"
                  elif version_gt $required_version $installed_version; then
                    echo "Updating $package from $installed_version to $required_version"
                    pip install --upgrade "$package==$required_version"
                  else
                    echo "$package is already at version $installed_version (required: $required_version)"
                  fi
                }

                # List of packages and their required versions
                packages="azure-ai-ml:1.1.0 azure-common:1.1.28 azure-core:1.26.1 azure-identity:1.10.0 azure-mgmt-core:1.3.0 azure-storage-blob:12.14.1 azure-storage-file-datalake:12.9.1 azure-storage-file-share:12.7.0"

                # Check and install packages if necessary
                echo "$packages" | tr ' ' '\n' | while IFS=':' read -r package version; do
                  check_and_install "$package" "$version"
                done

                # Update these packages to latest versions
                pip install --upgrade pyOpenSSL cryptography requests

                # Display Azure CLI version
                az version

                echo "Azure CLI and dependencies installation completed."

            env:
              PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)
          - task: AzureCLI@2
            displayName: Install AML CLI v2
            inputs:
              azureSubscription: 'Azure-ARM-Prod'
              scriptType: bash
              scriptLocation: inlineScript
              workingDirectory: $(System.DefaultWorkingDirectory)
              inlineScript: |
                set -e # fail on error
                
                # Check if we're in the virtual environment, activate only if needed
                if [[ "$VIRTUAL_ENV" != */myagent/$(virtual_environment) ]]; then
                  echo "Activating $(virtual_environment) virtual environment"
                  source ~/myagent/$(virtual_environment)/bin/activate
                else
                  echo "Already in $(virtual_environment) virtual environment"
                fi
                
                echo "Python version: $(python --version)"
                echo "Pip version: $(pip --version)"

                # Display Azure CLI version
                az version

                # Add and update the ml extension
                az extension  add -n ml

                # List all extensions
                az extension list

                echo "AML CLI v2 installation completed."

            env:
              PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

          - task: AzureCLI@2
            displayName: Connect to Workspace using CLI v2
            inputs:
              azureSubscription: 'Azure-ARM-Prod'
              scriptType: bash
              scriptLocation: inlineScript
              inlineScript: |
                az configure --defaults group=rg-$(Build.Repository.Name)-0001prod workspace=mlw-$(Build.Repository.Name)-0001prod
                currentId=$(az account show -o tsv --query id | tr -d '"\r')
                echo "##vso[task.setvariable variable=subscription_id;]$currentId"
                JSON_STRING=$'{\n\t"subscription_id": "%s",\n\t"resource_group": "%s",\n\t"workspace_name": "%s"\n}'
                printf "$JSON_STRING" "$currentId" "rg-$(Build.Repository.Name)-0001prod" "mlw-$(Build.Repository.Name)-0001prod"
                printf "$JSON_STRING" "$currentId" "rg-$(Build.Repository.Name)-0001prod" "mlw-$(Build.Repository.Name)-0001prod" > config.json
          - task: AzureCLI@2
            displayName: 'Register Model in Staging'
            inputs:
              azureSubscription: 'Azure-ARM-Prod'
              scriptType: 'bash'
              scriptLocation: 'inlineScript'
              inlineScript: |
                # Check if the virtual environment exists, create if it doesn't
                if [ ! -d ~/myagent/$(virtual_environment) ]; then
                  echo "Creating virtual environment $(virtual_environment)"
                  python3 -m venv ~/myagent/$(virtual_environment)
                else
                  echo "Virtual environment $(virtual_environment) already exists"
                fi
                # Activate the virtual environment
                echo "Activating $(virtual_environment) virtual environment"
                source ~/myagent/$(virtual_environment)/bin/activate                
                model_dir=$(Pipeline.Workspace)/latestTrainedModel/automl-model/automl-model
                
                if [ ! -d "$model_dir" ]; then
                  echo "Error: MLflow model directory not found"
                  exit 1
                fi
                
                az ml model create \
                  --name "$(ds_environment)-model" \
                  --path "$model_dir" \
                  --type "mlflow_model"
            env:
              PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

================
File: mlops-ado-pipelines/stage-batch-endpoint.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

name: batch-endpoint

variables:
  - template: ../../infrastructure/env-variables/config-infra-stage.yml
  - name: version
    value: ado-aml-cli-v2-templates
  - name: endpoint_name
    value: $(Build.Repository.Name)-batch-$(namespace)$(postfix)$(environment)
  - name: endpoint_type
    value: batch

trigger: none

pool:
  name: Default

stages:
  - stage: CreateBatchEndpoint
    displayName: Create/Update Batch Endpoint
    jobs:
      - job: DeployBatchEndpoint
        steps:
          - template: ../ado-aml-cli-v2-templates/install-az-cli.yml
          - template: ../ado-aml-cli-v2-templates/install-aml-cli.yml
          - template: ../ado-aml-cli-v2-templates/connect-to-workspace.yml
          - template: ../ado-aml-cli-v2-templates/create-compute.yml
            parameters:
              cluster_name: batch-cluster # name must match cluster name in deployment file below
              size: STANDARD_DS3_V2
              min_instances: 0
              max_instances: 5
              cluster_tier: dedicated
          - template: ../ado-aml-cli-v2-templates/create-endpoint.yml
            parameters:
              endpoint_file: $(Build.SourcesDirectory)/amlws-assets/endpoints/batch/batch-endpoint.yml
          - template: ../ado-aml-cli-v2-templates/create-deployment.yml
            parameters:
              deployment_name: $(Build.Repository.Name)-batch-dp
              deployment_file: $(Build.SourcesDirectory)/amlws-assets/endpoints/batch/batch-deployment.yml
          - template: ../ado-aml-cli-v2-templates/test-deployment.yml
            parameters:
              deployment_name: $(Build.Repository.Name)-batch-dp
              sample_request: $(Build.SourcesDirectory)/amlws-assets/data/batch.csv
              request_type: uri_file #either uri_folder or uri_file

================
File: mlops-ado-pipelines/stage-model-testing.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. Test 1

name: stage-model-testing

variables:
  - template: ../infrastructure/env-variables/config-infra-stage.yml
  - name: version
    value: ado-aml-cli-v2-templates
  - name: modelname
    value: automl

trigger: none

pool:
  name: Default

stages:
  - stage: EvaluateModelInStage
    displayName: Evaluate Model in Stage Environment
    jobs:
      - job: EvaluateModel
        timeoutInMinutes: 60
        steps:
          - template: ../ado-aml-cli-v2-templates/install-az-cli.yml
          - template: ../ado-aml-cli-v2-templates/install-aml-cli.yml
          - template: ../ado-aml-cli-v2-templates/connect-to-workspace.yml
          - template: ../ado-aml-cli-v2-templates/register-environment.yml
            parameters:
              environment_name: $(ds_environment)-env
              environment_file: $(Build.SourcesDirectory)/amlws-assets/environment/$(ds_environment)-env.yml
          - template: ../ado-aml-cli-v2-templates/create-compute.yml
            parameters:
              cluster_name: cpu-cluster
              size: Standard_DS3_v2
              min_instances: 0
              max_instances: 4
              cluster_tier: low_priority
          - template: ../ado-aml-cli-v2-templates/register-data.yml
            parameters:
              data_type: uri_file
              data_name: data
              data_file: $(ds_data)
          - template: ../ado-aml-cli-v2-templates/run-pipeline.yml
            parameters:
              pipeline_file: $(pipeline_file)
              experiment_name: stage_$(Build.Repository.Name)_evaluate_$(Build.SourceBranchName)
              display_name: stage_$(Build.Repository.Name)_run_$(Build.BuildID)
              enable_monitoring: $(enable_monitoring)
              modelname: ${{ variables.modelname }}

================
File: mlops-ado-pipelines/stage-online-endpoint.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

name: online-endpoint

variables:
  - template: ../infrastructure/env-variables/config-infra-stage.yml
  - name: endpoint_name
    value: $(Build.Repository.Name)-online-$(environment)-$(Build.BuildID)
  - name: deployment_name
    value: $(Build.Repository.Name)-online-$(environment)-$(Build.BuildID)-dp
  - name: endpoint_type
    value: online

trigger: none

pool:
  name: Default

stages:
  - stage: CreateOnlineEndpoint
    displayName: Create/Update Online Endpoint
    jobs:
      - job: DeployOnlineEndpoint
        steps:
          - template: ../ado-aml-cli-v2-templates/install-az-cli.yml
          - template: ../ado-aml-cli-v2-templates/install-aml-cli.yml
          - template: ../ado-aml-cli-v2-templates/connect-to-workspace.yml
          - template: ../ado-aml-cli-v2-templates/create-endpoint.yml
            parameters:
              endpoint_file: $(Build.SourcesDirectory)/amlws-assets/endpoints/online/online-endpoint.yml
          - template: ../ado-aml-cli-v2-templates/create-deployment.yml
            parameters:
              deployment_name: $(Build.Repository.Name)-online-dp
              deployment_file: $(Build.SourcesDirectory)/amlws-assets/endpoints/online/online-deployment.yml
          - template: ../ado-aml-cli-v2-templates/allocate-traffic.yml
            parameters:
              traffic_allocation: $(Build.Repository.Name)-online-dp=100
          - template: ../ado-aml-cli-v2-templates/test-deployment.yml
            parameters:
              deployment_name: $(Build.Repository.Name)-online-dp
              sample_request: $(Build.SourcesDirectory)/amlws-assets/data/request.json
              request_type: json

================
File: mlops-ado-pipelines/stage-register-in-staging.yml
================
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

name: register-in-staging

variables:
  - template: ../infrastructure/env-variables/config-infra-dev.yml
  
trigger: none

pool:
  name: Default

stages:
  - stage: DownloadLatestModelFromDev
    displayName: Download Latest Model from Dev
    jobs:
      - job: DownloadModel
        steps:
          - task: AzureCLI@2
            displayName: Install AZ ML dependencies
            inputs:
              azureSubscription: 'Azure-ARM-Dev'
              scriptType: bash
              scriptLocation: inlineScript
              workingDirectory: $(System.DefaultWorkingDirectory)
              inlineScript: |
                set -e # fail on error
                
                # Check if the virtual environment exists, create if it doesn't
                if [ ! -d ~/myagent/$(virtual_environment) ]; then
                  echo "Creating virtual environment $(virtual_environment)"
                  python3 -m venv ~/myagent/$(virtual_environment)
                else
                  echo "Virtual environment $(virtual_environment) already exists"
                fi

                # Check if we're in the virtual environment, activate only if needed
                if [[ "$VIRTUAL_ENV" != */myagent/$(virtual_environment) ]]; then
                  echo "Activating $(virtual_environment) virtual environment"
                  source ~/myagent/$(virtual_environment)/bin/activate
                else
                  echo "Already in $(virtual_environment) virtual environment"
                fi
                
                echo "Python version: $(python --version)"
                echo "Pip version: $(pip --version)"

                # Upgrade pip, setuptools, and wheel
                python -m pip install --upgrade pip setuptools wheel
                # Install or upgrade azure-cli
                python -m pip install --upgrade azure-cli

                # Function to compare versions
                version_gt() { test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1"; }

                # Function to check and install package
                check_and_install() {
                  package=$1
                  required_version=$2
                  installed_version=$(pip show $package 2>/dev/null | grep Version | cut -d ' ' -f 2)
                  
                  if [ -z "$installed_version" ]; then
                    echo "Installing $package $required_version"
                    pip install "$package==$required_version"
                  elif version_gt $required_version $installed_version; then
                    echo "Updating $package from $installed_version to $required_version"
                    pip install --upgrade "$package==$required_version"
                  else
                    echo "$package is already at version $installed_version (required: $required_version)"
                  fi
                }

                # List of packages and their required versions
                packages="azure-ai-ml:1.1.0 azure-common:1.1.28 azure-core:1.26.1 azure-identity:1.10.0 azure-mgmt-core:1.3.0 azure-storage-blob:12.14.1 azure-storage-file-datalake:12.9.1 azure-storage-file-share:12.7.0"

                # Check and install packages if necessary
                echo "$packages" | tr ' ' '\n' | while IFS=':' read -r package version; do
                  check_and_install "$package" "$version"
                done

                # Update these packages to latest versions
                pip install --upgrade pyOpenSSL cryptography requests

                # Display Azure CLI version
                az version

                echo "Azure CLI and dependencies installation completed."

            env:
              PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)
          - task: AzureCLI@2
            displayName: Install AML CLI v2
            inputs:
              azureSubscription: 'Azure-ARM-Dev'
              scriptType: bash
              scriptLocation: inlineScript
              workingDirectory: $(System.DefaultWorkingDirectory)
              inlineScript: |
                set -e # fail on error
                
                # Check if we're in the virtual environment, activate only if needed
                if [[ "$VIRTUAL_ENV" != */myagent/$(virtual_environment) ]]; then
                  echo "Activating $(virtual_environment) virtual environment"
                  source ~/myagent/$(virtual_environment)/bin/activate
                else
                  echo "Already in $(virtual_environment) virtual environment"
                fi
                
                echo "Python version: $(python --version)"
                echo "Pip version: $(pip --version)"

                # Display Azure CLI version
                az version

                # Add and update the ml extension
                az extension  add -n ml

                # List all extensions
                az extension list

                echo "AML CLI v2 installation completed."

            env:
              PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)
              
          - task: AzureCLI@2
            displayName: Connect to AML Workspace using CLI v2
            inputs:
              azureSubscription: 'Azure-ARM-Dev'
              scriptType: bash
              scriptLocation: inlineScript
              inlineScript: |
                az configure --defaults group=rg-$(Build.Repository.Name)-0001dev workspace=mlw-$(Build.Repository.Name)-0001dev
                currentId=$(az account show -o tsv --query id | tr -d '"\r')
                echo "##vso[task.setvariable variable=subscription_id;]$currentId"
                JSON_STRING=$'{\n\t"subscription_id": "%s",\n\t"resource_group": "%s",\n\t"workspace_name": "%s"\n}'
                printf "$JSON_STRING" "$currentId" "rg-$(Build.Repository.Name)-0001dev" "mlw-$(Build.Repository.Name)-0001dev"
                printf "$JSON_STRING" "$currentId" "rg-$(Build.Repository.Name)-0001dev" "mlw-$(Build.Repository.Name)-0001dev" > config.json
          - task: AzureCLI@2
            displayName: 'Download Latest Model from Dev'
            inputs:
              azureSubscription: 'Azure-ARM-Dev'
              scriptType: 'bash'
              scriptLocation: 'inlineScript'
              inlineScript: |
                set -e # fail on error
                
                # Check if the virtual environment exists, create if it doesn't
                if [ ! -d ~/myagent/$(virtual_environment) ]; then
                  echo "Creating virtual environment $(virtual_environment)"
                  python3 -m venv ~/myagent/$(virtual_environment)
                else
                  echo "Virtual environment $(virtual_environment) already exists"
                fi
                # Check if we're in the virtual environment, activate only if needed
                if [[ "$VIRTUAL_ENV" != */myagent/$(virtual_environment) ]]; then
                  echo "Activating $(virtual_environment) virtual environment"
                  source ~/myagent/$(virtual_environment)/bin/activate
                else
                  echo "Already in $(virtual_environment) virtual environment"
                fi
                #!/bin/bash

                # Set the model name
                MODEL_NAME="$(ds_environment)-model"

                echo "Fetching the latest version of model: $MODEL_NAME"

                # Get the latest version of the model
                latest_version=$(az ml model list \
                    --resource-group rg-$(Build.Repository.Name)-0001dev \
                    --workspace-name mlw-$(Build.Repository.Name)-0001dev \
                    --name $MODEL_NAME \
                    --query "max_by([], &version).version" \
                    -o tsv)

                if [ -z "$latest_version" ]; then
                    echo "Error: Unable to fetch the latest version for model $MODEL_NAME"
                    exit 1
                fi

                echo "Latest version of $MODEL_NAME is: $latest_version"

                echo "Attempting to download the latest version of the model"

                az ml model download \
                    --resource-group rg-$(Build.Repository.Name)-0001dev \
                    --workspace-name mlw-$(Build.Repository.Name)-0001dev \
                    --name $MODEL_NAME \
                    --version $latest_version \
                    --download-path "$(Build.ArtifactStagingDirectory)/model"

                if [ $? -ne 0 ]; then
                    echo "Error: Failed to download the latest version of the model. Please check the model availability and permissions."
                    echo "Attempting to get more information about the model..."
                    
                    az ml model show \
                        --resource-group rg-$(Build.Repository.Name)-0001dev \
                        --workspace-name mlw-$(Build.Repository.Name)-0001dev \
                        --name $MODEL_NAME \
                        --version $latest_version

                    exit 1
                fi

                echo "Model downloaded successfully to: $(Build.ArtifactStagingDirectory)/model"
                echo "Contents of downloaded directory:"
                ls -R $(Build.ArtifactStagingDirectory)/model

                # Verify the downloaded model
                echo "Model details:"
                az ml model show \
                    --resource-group rg-$(Build.Repository.Name)-0001dev \
                    --workspace-name mlw-$(Build.Repository.Name)-0001dev \
                    --name $MODEL_NAME \
                    --version $latest_version
            env:
              PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

          - publish: $(Build.ArtifactStagingDirectory)/model
            artifact: latestTrainedModel
            displayName: 'Publish Latest Trained Model'

  - stage: RegisterModelInStaging
    displayName: Register Model in Staging Environment
    dependsOn: DownloadLatestModelFromDev
    jobs:
      - job: RegisterModel
        steps:
          - checkout: self
            path: s/
          - download: current
            artifact: latestTrainedModel
            displayName: 'Download Latest Trained Model'
          - task: Bash@3
            inputs:
              targetType: 'inline'
              script: |
                echo "Contents of $(Pipeline.Workspace)/latestTrainedModel:"
                ls -R $(Pipeline.Workspace)/latestTrainedModel
            displayName: 'Debug: List Downloaded Artifact Contents'
          - task: AzureCLI@2
            displayName: Install AZ ML dependencies
            inputs:
              azureSubscription: 'Azure-ARM-Stage'
              scriptType: bash
              scriptLocation: inlineScript
              workingDirectory: $(System.DefaultWorkingDirectory)
              inlineScript: |
                set -e # fail on error
                
                # Check if the virtual environment exists, create if it doesn't
                if [ ! -d ~/myagent/$(virtual_environment) ]; then
                  echo "Creating virtual environment $(virtual_environment)"
                  python3 -m venv ~/myagent/$(virtual_environment)
                else
                  echo "Virtual environment $(virtual_environment) already exists"
                fi

                # Check if we're in the virtual environment, activate only if needed
                if [[ "$VIRTUAL_ENV" != */myagent/$(virtual_environment) ]]; then
                  echo "Activating $(virtual_environment) virtual environment"
                  source ~/myagent/$(virtual_environment)/bin/activate
                else
                  echo "Already in $(virtual_environment) virtual environment"
                fi
                
                echo "Python version: $(python --version)"
                echo "Pip version: $(pip --version)"

                # Upgrade pip, setuptools, and wheel
                python -m pip install --upgrade pip setuptools wheel
                # Install or upgrade azure-cli
                python -m pip install --upgrade azure-cli

                # Function to compare versions
                version_gt() { test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1"; }

                # Function to check and install package
                check_and_install() {
                  package=$1
                  required_version=$2
                  installed_version=$(pip show $package 2>/dev/null | grep Version | cut -d ' ' -f 2)
                  
                  if [ -z "$installed_version" ]; then
                    echo "Installing $package $required_version"
                    pip install "$package==$required_version"
                  elif version_gt $required_version $installed_version; then
                    echo "Updating $package from $installed_version to $required_version"
                    pip install --upgrade "$package==$required_version"
                  else
                    echo "$package is already at version $installed_version (required: $required_version)"
                  fi
                }

                # List of packages and their required versions
                packages="azure-ai-ml:1.1.0 azure-common:1.1.28 azure-core:1.26.1 azure-identity:1.10.0 azure-mgmt-core:1.3.0 azure-storage-blob:12.14.1 azure-storage-file-datalake:12.9.1 azure-storage-file-share:12.7.0"

                # Check and install packages if necessary
                echo "$packages" | tr ' ' '\n' | while IFS=':' read -r package version; do
                  check_and_install "$package" "$version"
                done

                # Update these packages to latest versions
                pip install --upgrade pyOpenSSL cryptography requests

                # Display Azure CLI version
                az version

                echo "Azure CLI and dependencies installation completed."

            env:
              PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)
          - task: AzureCLI@2
            displayName: Install AML CLI v2
            inputs:
              azureSubscription: 'Azure-ARM-Stage'
              scriptType: bash
              scriptLocation: inlineScript
              workingDirectory: $(System.DefaultWorkingDirectory)
              inlineScript: |
                set -e # fail on error
                
                # Check if we're in the virtual environment, activate only if needed
                if [[ "$VIRTUAL_ENV" != */myagent/$(virtual_environment) ]]; then
                  echo "Activating $(virtual_environment) virtual environment"
                  source ~/myagent/$(virtual_environment)/bin/activate
                else
                  echo "Already in $(virtual_environment) virtual environment"
                fi
                
                echo "Python version: $(python --version)"
                echo "Pip version: $(pip --version)"

                # Display Azure CLI version
                az version

                # Add and update the ml extension
                az extension  add -n ml

                # List all extensions
                az extension list

                echo "AML CLI v2 installation completed."

            env:
              PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

          - task: AzureCLI@2
            displayName: Connect to Workspace using CLI v2
            inputs:
              azureSubscription: 'Azure-ARM-Stage'
              scriptType: bash
              scriptLocation: inlineScript
              inlineScript: |
                az configure --defaults group=rg-$(Build.Repository.Name)-0001stage workspace=mlw-$(Build.Repository.Name)-0001stage
                currentId=$(az account show -o tsv --query id | tr -d '"\r')
                echo "##vso[task.setvariable variable=subscription_id;]$currentId"
                JSON_STRING=$'{\n\t"subscription_id": "%s",\n\t"resource_group": "%s",\n\t"workspace_name": "%s"\n}'
                printf "$JSON_STRING" "$currentId" "rg-$(Build.Repository.Name)-0001stage" "mlw-$(Build.Repository.Name)-0001stage"
                printf "$JSON_STRING" "$currentId" "rg-$(Build.Repository.Name)-0001stage" "mlw-$(Build.Repository.Name)-0001stage" > config.json
          - task: AzureCLI@2
            displayName: 'Register Model in Staging'
            inputs:
              azureSubscription: 'Azure-ARM-Stage'
              scriptType: 'bash'
              scriptLocation: 'inlineScript'
              inlineScript: |
                # Check if the virtual environment exists, create if it doesn't
                if [ ! -d ~/myagent/$(virtual_environment) ]; then
                  echo "Creating virtual environment $(virtual_environment)"
                  python3 -m venv ~/myagent/$(virtual_environment)
                else
                  echo "Virtual environment $(virtual_environment) already exists"
                fi
                # Activate the virtual environment
                echo "Activating $(virtual_environment) virtual environment"
                source ~/myagent/$(virtual_environment)/bin/activate                
                model_dir=$(Pipeline.Workspace)/latestTrainedModel/automl-model/automl-model
                
                if [ ! -d "$model_dir" ]; then
                  echo "Error: MLflow model directory not found"
                  exit 1
                fi
                
                az ml model create \
                  --name "$(ds_environment)-model" \
                  --path "$model_dir" \
                  --type "mlflow_model"
            env:
              PYTHONPATH: ~/myagent/$(virtual_environment)/lib/python3.12/site-packages:$(PYTHONPATH)

================
File: README.md
================
# Azure DevOps MLOps Template for Classical Machine Learning

**Description:**  
This repository provides an Azure DevOps MLOps pipeline template for classical machine learning workflows. It is designed to automate key processes such as model training, evaluation, and deployment using Azure Machine Learning (AML) services. The pipeline operates on a self-hosted system pool instead of Azure's cloud-based pools.

This repository is based on the mlopsv2 accelerator repo by the Azure team https://github.com/Azure/mlops-v2/tree/main. It addresses and gets past certain errors encountered in the repo as well as uses an AutoML training pipeline for classical regression instead of random forest (still kept in train2.py). This is an ado-aml-cli-v2 version focused on classical machine learning using bicep as iac (other versions focused on a different type of machine learning/iac will be implemented at a later date).

## Table of Contents

1. [Getting Started](#getting-started)
2. [Prerequisites](#prerequisites)
3. [Installation and Setup](#installation-and-setup)
4. [Service Principal Setup](#service-principal-setup)
5. [Creating Azure DevOps Environments](#creating-azure-devops-environments)
6. [Directory Structure](#directory-structure)
7. [Project Structure](#project-structure)
8. [Python Pipeline Overview](#python-pipeline-overview)
9. [MLOps Pipelines and CI/CD Architecture](#mlops-ado-pipelines-and-cicd-architecture)
10. [Deploy and Execute Azure Machine Learning Pipelines](#deploy-and-execute-azure-machine-learning-pipelines)
11. [Usage](#usage)
12. [Contributing](#contributing)
13. [License](#license)

## Getting Started

This repository is designed for deploying and managing machine learning models using Azure DevOps, with a self-hosted agent for CI/CD. The templates automate the installation of required tools and facilitate end-to-end MLOps, from data registration to deployment.

## Prerequisites

Before running the pipeline, ensure that you have the following:

- **Self-hosted Azure DevOps Agent**: A self-hosted system to run Azure DevOps pipelines. (this repo uses a macOS self-hosted agent) https://learn.microsoft.com/en-us/azure/devops/pipelines/agents/osx-agent?view=azure-devops
- **Azure Subscription**: Access to necessary Azure Machine Learning resources.
- **Python 3.12** installed on the self-hosted system.
- **Azure CLI** and **AML CLI**, which will be installed automatically by the pipeline templates.

## Installation and Setup

The templates in the `ado-aml-cli-v2-templates` folder handle most of the installation and setup steps automatically.

- **Azure CLI and AML CLI**: Use `install-az-cli.yml` and `install-aml-cli.yml` to install Azure CLI, AML CLI, and required extensions.
- **Compute Cluster**: The `create-compute.yml` template ensures that the necessary Azure Machine Learning compute resources are provisioned.
- **Workspace Connection**: The `connect-to-workspace.yml` connects the self-hosted system to the Azure Machine Learning workspace, allowing it to manage and deploy models.

## Service Principal Setup

For Azure DevOps pipelines to create Azure Machine Learning infrastructure, deploy, and execute AML pipelines, it is necessary to create an Azure service principal for each Azure ML environment (Dev, Stage, and Prod). These service principals can be created using the Azure Cloud Shell:

1. **Launch the Azure Cloud Shell**

   - Open the [Azure Cloud Shell](https://shell.azure.com/).
   - If prompted, choose **Bash** as the environment.
   - If this is your first time using Cloud Shell, you will be required to create a storage account for it.

2. **Prepare and Run the Bash Commands**
   Update the variables in the following script and run it in the Cloud Shell:

   ```bash
   projectName="<your project name>"
   roleName="Contributor"
   subscriptionId="<subscription Id>"
   environment="<Dev|Stage|Prod>" # Capitalize the first letter
   servicePrincipalName="Azure-ARM-${environment}-${projectName}"

   echo "Using subscription ID $subscriptionId"
   echo "Creating SP for RBAC with name $servicePrincipalName, with role $roleName and in scope /subscriptions/$subscriptionId"

   az ad sp create-for-rbac --name $servicePrincipalName --role $roleName --scopes /subscriptions/$subscriptionId
   echo "Please ensure that the information created here is properly saved for future use."
   ```

3. **Save the Output**
   Save the output containing the service principal credentials securely.

4. **Repeat for Each Environment**
   Repeat these steps for each environment (Dev, Stage, and Prod).

5. **Configure Azure DevOps Service Connections**
   Use the service principal credentials to create service connections in Azure DevOps.

## Creating Azure DevOps Environments

The pipelines in each branch of your ML project repository will depend on Azure DevOps environments. These environments should be created before deployment.

To create the Dev, Stage, and Prod environments:

1. **Create New Environments**

   - In Azure DevOps, select Pipeline in the left menu and then select Environments.
   - Select New Environment.

2. **Name the Environments**
   - Create three environments named dev, stage, and prod.
   - Click Create for each.

The environments will initially be empty and indicate "Never deployed," but this status will update after the first deployment.

Once the environments are created, you are ready to deploy your Azure Machine Learning infrastructure and execute the ML training and model deployment pipelines.

## Directory Structure

```plaintext
ado-aml-cli-v2-templates/
  ├── allocate-traffic.yml              # YAML template for allocating traffic between model versions.
  ├── connect-to-workspace.yml          # Template to connect to an Azure ML workspace.
  ├── create-compute.yml                # Template to create necessary Azure ML compute resources.
  ├── create-deployment.yml             # YAML file to handle the deployment of models.
  ├── create-endpoint.yml               # Template to create endpoints for deployed models.
  ├── install-aml-cli.yml               # Template to install Azure Machine Learning CLI.
  ├── install-az-cli.yml                # Template to install Azure CLI.
  ├── register-data.yml                 # Template to register datasets in Azure ML.
  ├── register-environment.yml          # Template to register environments in Azure ML.
  ├── run-pipeline.yml                  # Template to run the main pipeline.
  ├── test-deployment.yml               # Template for testing the deployment of models.

amlws-assets/
  ├── data/                              # Directory for datasets used in the project.
  │   ├── batch.csv                     # Batch input dataset for model training.
  │   ├── data.csv                      # Main dataset for training and evaluation.
  │   ├── data.yml                      # YAML file containing metadata for the main dataset.
  │   ├── request.json                  # Sample request file for batch scoring.
  │   ├── stage.csv                     # Test Dataset for staging environment.
  │   └── stage.yml                     # YAML file containing metadata for the staging dataset.
  ├── endpoints/                         # Directory for deployment pipelines.
  │   ├── batch/                          # Subdirectory for batch deployment pipelines.
  │   │   ├── batch-deployment.yml      # Pipeline for deploying batch models.
  │   │   └── batch-endpoint.yml        # Pipeline for setting up batch endpoints.
  │   └── online/                         # Subdirectory for online deployment pipelines.
  │       ├── online-deployment.yml     # Pipeline for deploying online models.
  │       └── online-endpoint.yml       # Pipeline for setting up online endpoints.
  ├── environment/                       # Directory for environment configurations.
  │   ├── automl-conda.yml              # Conda environment configuration for AutoML.
  │   ├── automl-env.yml                # YAML file for the AutoML environment.
  │   ├── train-conda.yml               # Conda environment configuration for training.
  │   └── train-env.yml                 # YAML file for the training environment.
  ├── pipelinejobs/                       # Directory for evaluation pipelines.
  │   ├── stage-test.yml                # Pipeline for testing models in the staging environment.
  │   └── dev-train.yml                 # Pipeline for training models in the development environment.
  ├── src/                               # Source code for the project.
  │   ├── evaluate.py                   # Script to evaluate the performance of models.
  │   ├── prep.py                       # Script for data preparation and preprocessing.
  │   ├── register.py                   # Script to register trained models in Azure ML.
  │   ├── stageprep.py                  # Script for staging-specific data preparation.
  │   ├── train.py                      # Script for training models using AutoML.
  │   └── train2.py                     # Script for training models using RandomForestRegressor.

infrastructure/
  ├── env-variables/                     # Directory for environment variable configurations.
  │   ├── config-infra-dev.yml          # Configuration file for the Dev environment.
  │   ├── config-infra-prod.yml         # Configuration file for the Prod environment.
  │   └── config-infra-stage.yml        # Configuration file for the Stage environment.
  ├── modules/                           # Bicep modules for infrastructure setup.
  │   ├── aml_computecluster.bicep      # Bicep template for creating AML compute clusters.
  │   ├── aml_workspace.bicep           # Bicep template for creating AML workspaces.
  │   ├── application_insights.bicep    # Bicep template for setting up Application Insights.
  │   ├── container_registry.bicep      # Bicep template for creating a container registry.
  │   ├── key_vault.bicep               # Bicep template for creating Azure Key Vault.
  │   └── storage_account.bicep         # Bicep template for creating a storage account.
  ├── pipelines/                         # Directory for infrastructure deployment pipelines.
  │   └── bicep-ado-deploy-infra.yml    # YAML template for deploying infrastructure using Bicep.

mlops-ado-pipelines/
  ├── dev-model-training.yml             # Main development model training pipeline.
  ├── prod-batch-endpoint.yml            # Production batch endpoint deployment pipeline.
  ├── prod-online-endpoint.yml           # Production online endpoint deployment pipeline.
  ├── prod-register-in-production.yml    # Production model registration pipeline.
  ├── stage-batch-endpoint.yml           # Staging batch endpoint deployment pipeline.
  ├── stage-model-testing.yml            # Staging model testing pipeline.
  ├── stage-online-endpoint.yml          # Staging online endpoint deployment pipeline.
  └── stage-register-in-staging.yml      # Staging model registration pipeline.
```

## Project Structure

The repository is organized into several key directories:

### ado-aml-cli-v2-templates/

Contains YAML templates for managing Azure resources, including the creation of compute resources, deployments, and connections to the Azure Machine Learning workspace.

### amlws-assets/

This directory includes all components related to data preparation and model training:

- **data/**: Contains datasets used for training and evaluation, along with metadata files.
- **environment/**: Holds configurations for the Conda environments used in training and AutoML.
- **src/**: Contains the main source code scripts responsible for data preparation, training, evaluation, and model registration.

### infrastructure/

This folder is dedicated to the infrastructure setup for the Azure resources:

- **env-variables/**: Contains configuration files for different environments (Dev, Stage, Prod).
- **modules/**: Houses Bicep modules for resource creation, such as Azure ML workspaces and compute clusters.
- **pipelines/**: Includes YAML files for deploying infrastructure using Bicep.

### mlops-ado-pipelines/

This directory contains the main Azure DevOps pipelines for MLOps processes:

- **deploy/**: Subdirectories for batch and online deployment pipelines, including the necessary YAML files.
- **evaluate/**: Contains testing and training pipelines for evaluating and training models.
- **Main Pipelines**: YAML files for development, staging, and production pipelines that automate model training, deployment, and registration.

## Python Pipeline Overview

This repository includes several Python scripts that handle key stages of the machine learning workflow, including data preparation, evaluation, and model registration. These scripts are integrated into the Azure DevOps pipeline, facilitating automation and efficiency throughout the ML lifecycle.

### Key Python Scripts

1. **`train.py` - AutoML Training Pipeline**  
   This script utilizes Azure AutoML to train a classical regression model, selecting the best model and hyperparameters based on the dataset provided.

2. **`train2.py` - Custom RandomForestRegressor Training**  
   This script focuses on training a RandomForest model for regression, allowing manual tuning and feature engineering.

3. **`prep.py` - Data Preparation**  
   This script is responsible for preprocessing the data before it is fed into the training pipelines. Key features include:

   - Data Cleaning
   - Feature Engineering
   - Normalization/Scaling
   - Dataset Splitting

4. **`evaluate.py` - Model Evaluation**  
   This script evaluates the performance of trained models based on validation metrics. Key functions include:

   - Performance Metrics Calculation
   - Model Comparison
   - Visualization

5. **`register.py` - Model Registration**  
   This script is used to register trained models into the Azure Machine Learning workspace. Key features include:

   - Model Versioning
   - Metadata Logging
   - Deployment Preparation

6. **`stageprep.py` - Staging Data Preparation**  
   Similar to `prep.py`, this script prepares data specifically for the staging environment.

### Integration into Azure DevOps Pipelines

All these scripts are integrated into the Azure DevOps pipeline, ensuring a seamless workflow from data preparation to model deployment.

### Customization Options

- **Data Processing Logic**: Each of the preparation scripts can be customized to include specific data transformations, feature selections, or additional preprocessing steps that are relevant to your use case.
- **Evaluation Criteria**: You can modify `evaluate.py` to include specific performance metrics that are more aligned with your project's goals.

## MLOps Pipelines and CI/CD Architecture

### MLOps Pipelines

The repository includes several pipelines that automate key stages of the machine learning lifecycle:

- **Development Pipeline**

  - `dev-model-training.yml`: Automates model training, data registration, and initial evaluation.

- **Staging Pipelines**

  - `stage-batch-endpoint.yml`: Deploys models to batch endpoints for staging.
  - `stage-online-endpoint.yml`: Deploys models to online endpoints for real-time inference in staging.
  - `stage-model-testing.yml`: Tests the deployed model in the staging environment.
  - `stage-register-in-staging.yml`: Registers models into the staging registry.

- **Production Pipelines**
  - `prod-batch-endpoint.yml`: Deploys the approved model to production batch endpoints.
  - `prod-online-endpoint.yml`: Deploys models to online endpoints for real-time inference in production.
  - `prod-register-in-production.yml`: Registers the final model into the production registry.

### CI/CD Architecture

The repository is designed around a CI/CD pipeline to streamline the development, testing, and deployment of machine learning models:

- **Continuous Integration (CI)**: The development pipeline is triggered with every code commit.
- **Continuous Deployment (CD)**: Deployment pipelines automate the process of moving models through different environments.
- **Model Registry**: Models are registered in different environments using dedicated pipelines.
- **Self-hosted Agent Pool**: The CI/CD process runs on a self-hosted agent pool for better control and integration with on-premise systems.

## Deploy and Execute Azure Machine Learning Pipelines

Now that your ML project is created, follow these steps to deploy and execute the pipelines:

1. **Deploy Azure Machine Learning Infrastructure**

   - Go to your project repository (e.g., taxi-fare-regression).
   - Customize the `config-infra-dev.yml`, `config-infra-stage.yml`, and `config-infra-prod.yml` files to define unique Azure resource groups and Azure ML workspaces for your project in each environment.
   - Run the infrastructure deployment pipeline (`bicep-ado-deploy-infra.yml`) to deploy the Azure Machine Learning resources (e.g., resource groups, workspaces, compute clusters) for each environment.

2. **Deploy and Manage Pipelines**
   - Once infrastructure is deployed, deploy the ML training and model deployment pipelines in the respective environments.
   - Manage the development of the model training pipeline in the Dev environment.
   - When the model is validated in the Dev environment, promote it to the Stage environment for further testing.
   - After successful validation in the Stage environment, promote the model to the Prod environment through pull requests and run the model deployment pipeline.

## Usage

To run the pipeline:

1. **Trigger the Development Pipeline**: Navigate to the Pipelines section in Azure DevOps and trigger the `dev-model-training.yml` pipeline.
2. **Deploy to Staging**: Use the staging pipelines to deploy your model to the staging environment.
3. **Deploy to Production**: After successful staging validation, use the production pipelines to deploy the model into the production environment.
4. **Register Models**: Use the registration pipelines to handle the registration of models in the respective environments.

## Contributing

To contribute:

1. Fork the repository.
2. Create a new branch (`git checkout -b feature-branch`).
3. Make your changes and commit them (`git commit -m 'Feature description'`).
4. Push to the branch (`git push origin feature-branch`).
5. Create a new Pull Request.

## License

This project is licensed under the MIT License. See `LICENSE` for more details.
